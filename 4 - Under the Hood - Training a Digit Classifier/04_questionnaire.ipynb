{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM/qU57GFIKxrJZq08PfNqD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ferjorosa/learn-fastai/blob/main/fastbook_ch4_questionnaire.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIvkSgRhFpjK"
      },
      "source": [
        "# Questionnaire Chapter 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6YOhyQk5Jb4",
        "outputId": "84a5b0a1-75e3-4962-a9ee-58b677314eb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#hide (Google Colab)\n",
        "!pip install fastai --upgrade -q\n",
        "import fastai\n",
        "print(fastai.__version__)\n",
        "\n",
        "!pip install -Uqq fastbook\n",
        "import fastbook\n",
        "fastbook.setup_book()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |█▊                              | 10 kB 20.9 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 20 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 30 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |███████                         | 40 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 51 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 61 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 71 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 81 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 92 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 102 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 112 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 122 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 133 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 143 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 153 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 163 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 174 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 184 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 189 kB 4.1 MB/s \n",
            "\u001b[?25h\u001b[?25l\r\u001b[K     |█████▊                          | 10 kB 20.5 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 20 kB 27.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 30 kB 35.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 40 kB 39.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 51 kB 38.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 56 kB 4.0 MB/s \n",
            "\u001b[?25h2.5.3\n",
            "\u001b[K     |████████████████████████████████| 720 kB 4.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 37.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 46 kB 3.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 51 kB 283 kB/s \n",
            "\u001b[?25hMounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTjU-xAHKGdq"
      },
      "source": [
        "**Question 1: How is a grayscale image represented on a computer? How about a color image?**\n",
        "\n",
        "A grayscale image is represented using a matrix, whose size corresponds to the number of pixels, where each matrix is ranged in [0,255].\n",
        "\n",
        "A color image is represented using a rank 3 tensor with 3 channels (red, green, blue), where each channel considers a matrix whose values correspond to the [0,255] range."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpy1b5TlKuYS"
      },
      "source": [
        "**Question 2: How are the fields and folders of the MNIST_SAMPLE dataset structured? Why?**\n",
        "\n",
        "Each image has its own folder. For example threes are stored in the \"threes\" fold. In addition, image folders are divided into train and validation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUpwJJImLEGZ"
      },
      "source": [
        "**Question 3: Explain how the pixel similarity approach to classifying digits works**\n",
        "\n",
        "For each number, we estimate an \"ideal\" image that corresponds to the mean values of each of its pixels. Then, in order to classify an image as a specific number, we estimate the distance between the new image and all of the ideal images considered. The image is assigned a class corresponding to the smallest distance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WX4N_VutFjaE"
      },
      "source": [
        "**Question 4: What is a list comprehension? Create one that selects odd numbers from a list and doubles them**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93cgoB9_FnaC"
      },
      "source": [
        "l = [2,3,4,5,6]\n",
        "\n",
        "[l[i]**2 for i in range(0, len(l), 2)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gaKY-eWLz2q"
      },
      "source": [
        "**Question 5: What is a rank-3 tensor?**\n",
        "\n",
        "It is a tensor with 3 dimensions. For example an RGB color image is a rank-3 tensor [i, j, k] where:\n",
        "* i: number of channels, i.e., 3 (red, green, blue)\n",
        "* j: number of row pixels\n",
        "* k: number of column pixels\n",
        "\n",
        "Example: [3, 20, 20] is a RGB image with dimension 20x20"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLAge2QsF2GT"
      },
      "source": [
        "**Question 6: What is the difference between tensor rank and shape? How do you get the rank from the shape**\n",
        "\n",
        "Tensor rank is defined as the number of dimensions of a tensor. On the other hand, tensor shape represents the size of the each dimension. For example, a tensor with rank 2 is a two-dimensional array whose dimension sizes may be 10x5 (i.e., [10, 5])"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xf0kcRE9F2Ri",
        "outputId": "aa0206bc-d068-4bf6-f018-dafed3a49779"
      },
      "source": [
        "import torch\n",
        "\n",
        "t = torch.tensor([[[1,2,3], [1,2,3]], [[3,4,5], [3,4,5]]])\n",
        "print(\"Shape: \" + str(t.shape))\n",
        "print(\"Rank: \" + str(t.ndim))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: torch.Size([2, 2, 3])\n",
            "Rank: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykNcGxw0JRTr",
        "outputId": "4e2480d8-c39f-4684-a7be-9a940885559d"
      },
      "source": [
        "torch.zeros([3,5,2]) #3 matrices of 5x2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0., 0.],\n",
              "         [0., 0.],\n",
              "         [0., 0.],\n",
              "         [0., 0.],\n",
              "         [0., 0.]],\n",
              "\n",
              "        [[0., 0.],\n",
              "         [0., 0.],\n",
              "         [0., 0.],\n",
              "         [0., 0.],\n",
              "         [0., 0.]],\n",
              "\n",
              "        [[0., 0.],\n",
              "         [0., 0.],\n",
              "         [0., 0.],\n",
              "         [0., 0.],\n",
              "         [0., 0.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuRBhtqhJpRD"
      },
      "source": [
        "**Question 7: What are RMSE and L1 norm?**\n",
        "* RMSE: root mean-squared error. It is defined as the square root of the average squared distance between the actual score and the predicted score:\n",
        "* L1 norm: manhattan distance. For two vectorx $\\mathbf{x}$ and $\\mathbf{y}$, it is defined as $\\sum_{i} |x_{i} - y_{i}|$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdaxDUYdO-pz"
      },
      "source": [
        "**Question 8: How can you apply a calculation on thousand os numbers at once many thousands of times faster than a Python loop?**\n",
        "\n",
        "We can speed calculations using vectorization. [More information](https://blog.paperspace.com/numpy-optimization-vectorization-and-broadcasting/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXizEBzhQMQL"
      },
      "source": [
        "**Question 9: Create a 3x3 tensor or array containing the numbers from 1 to 9. Double it. Select the bottom right four numbers**\n",
        "\n",
        "We use view instead of reshape to avoid the extra computation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqD6tZbHQZ6B",
        "outputId": "29963d33-ea63-48fd-86b8-5ff969d016ad"
      },
      "source": [
        "matrix = torch.arange(1,10).view([3,3])\n",
        "matrix_sq = matrix**2\n",
        "matrix_sq.view(3*3)[-4:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([36, 49, 64, 81])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOdwRvmLSCKZ"
      },
      "source": [
        "**Question 10: What is broadcasting?**\n",
        "\n",
        "*My answer:* When doing computations with vectors of unmatching dimensions, broadcasting is the process of temporarily expanding the dimension of the smaller tensor to match the dimension of the larger tensor\n",
        "\n",
        "*Proper answer:* The term broadcasting describes how numpy/pytorch treats tensors with different shapes during arithmetic operations. Subject to certain constraints, the smaller tensor is “broadcast” across the larger tensor so that they have compatible shapes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUmCXAabS_4y"
      },
      "source": [
        "**Question 11: Are metrics generally calculated using the training set or the validation set? Why?**\n",
        "\n",
        "We consider a loss function with the training data. We use metrics such as accuracy or RMSE with the validation data. Loss functions are better for optimization purposes. Metrics do not usually have a \"gradient\" nor are easy to directly optimize, so we use them in validation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wETbwDVLWBuB"
      },
      "source": [
        "**Question 12: What is SGD?**\n",
        "\n",
        "*My answer:* The stochastic gradient descent is a variant of the gradient descent where we use a random sample or batch to optimize the parameters of the function (instead of the whole training data)\n",
        "\n",
        "*Proper answer:* In both gradient descent (GD) and stochastic gradient descent (SGD), you update a set of parameters in an iterative manner to minimize an error function.\n",
        "\n",
        "While in GD, you have to run through ALL the samples in your training set to do a single update for a parameter in a particular iteration, in SGD, on the other hand, you use ONLY ONE or SUBSET of training sample from your training set to do the update for a parameter in a particular iteration. If you use SUBSET, it is called Minibatch Stochastic gradient Descent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f93HsJhW5oR"
      },
      "source": [
        "**Question 13: Why does SGD use mini-batches?**\n",
        "\n",
        "If the number of training samples is very large, then using gradient descent may take too long because in every iteration you are running through the complete training set. Instead, every iteration of SGD only considers a handful of training samples and updates the parameters with them.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RB70IIRCXtUh"
      },
      "source": [
        "**Question 14: What are the seven steos ub SGD for machine learning?**\n",
        "\n",
        "1. Initialize\n",
        "2. Predict\n",
        "3. Estimate loss\n",
        "4. Calculate gradient\n",
        "5. Update parameter values with gradient (i.e., step)\n",
        "6. Repeat the process\n",
        "7. Stop if the number of epochs is reached or if the loss did not decrease enough\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JW_DezUY2g5"
      },
      "source": [
        "**Question 15: How do we initialize the weights in a model?**\n",
        "\n",
        "There may be multiple approaches. In our case, we use random values. Andrew Ng proposes to use small random values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Go3W5Md_ZOpn"
      },
      "source": [
        "**Question 16: What is loss?**\n",
        "\n",
        "The loss function measures the ability of our model to represent and predict the training data. We use a function that can be easily optimized, usually via a gradient descent method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqSeaDbuZhTm"
      },
      "source": [
        "**Question 17: Why can't we always use a high learning rate?**\n",
        "\n",
        "The learning rate is a parameter of the gradient descent algorithm that establishes the \"step size\" of the algorithm. A learning rate that is too large can cause the model to converge too quickly to a suboptimal solution, whereas a learning rate that is too small can cause the process to get stuck."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QU12Dxy9anYC"
      },
      "source": [
        "**Question 18: What is a gradient?**\n",
        "\n",
        "In *mathematics*, the gradient of a function is another function that corresponds to its first derivative. However, in *deep learning* the gradient usually refers to the value of the function's derivative at a particular argument value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4bsONWUa2VY"
      },
      "source": [
        "**Question 19: Do you need to calculate gradients yourself?**\n",
        "\n",
        "By using Pytorch and other libraries with automatic differentiation, we are not required to know how to estimate the gradients ourselves."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNgOh-oebnXQ"
      },
      "source": [
        "**Question 20: Why can't we use accuracy as a loss function?**\n",
        "\n",
        "Because its gradient could not be optimized."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7TIb-doiFNM"
      },
      "source": [
        "**Question 21: What is special about the sigmoid function?**\n",
        "\n",
        "The sigmoid is a symmetric function with a maximum value of 1.0 and a minimum value of 0.0, which makes it appropriate for probabilistic binary classification problems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjyW2nlpid17"
      },
      "source": [
        "**Question 22: What is the difference between a loss function and a metric?**\n",
        "\n",
        "A loss function can be easily optimized via gradient descent but it is not easily interpretable by humans. On the other hand, a metric is easily interpreted but it is diffuclt to optimize. For example classification accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjTLrrFZi5Cd"
      },
      "source": [
        "**Question 23: What is the function to calculate new weights using a learning rate?**\n",
        "\n",
        "The gradient descent method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13MB6dxFjFND"
      },
      "source": [
        "**Question 24: What does the ```DataLoader``` class do?**\n",
        "\n",
        "It allows to iterate through a dataset using the Pytorch library."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKh38_e_k9B6"
      },
      "source": [
        "**Question 25: Write pseudocode showing the basic steps taken in each epoch of SGD?**\n",
        "\n",
        "The pseudocode of the traditional SGD algorithm is the following:\n",
        "\n",
        "1. Initialize the weights $w$ and introduce the learning rate $l$ and data $\\mathcal{D}$.\n",
        "2. For each iteration $t \\in [1, \\dots, T]$:\n",
        "  * Draw a random instance $x$ with replacement from the data $\\mathcal{D}$\n",
        "  * Use current weights to predict the value of the target variable\n",
        "  * Compute the loss\n",
        "  * Compute the gradients $g$\n",
        "  * Update weight values with the gradient $w = w - (g * l)$\n",
        "\n",
        "The implementation used by Pytorch is other, which combines ideas from SGD and from mini-batch gradient descent:\n",
        "\n",
        "1. Initialize the weights $w$, introduce the learning rate $l$, the data $\\mathcal{D}$, and the mini-batch size $m$.\n",
        "2. For epoch $e \\in [1, \\dots, E]$:\n",
        "  * Suffle $\\mathcal{D}$ to prevent cycles.\n",
        "  * Generate a batch of size $m$ with instances sampled without replacement\n",
        "  * Use current weights to predict the values of the target variables in the mini-batch\n",
        "  * Compute the loss using the mini-batch\n",
        "  * Compute the gradient $g$ using the mini-batch\n",
        "  * Update weight values with the gradient $w = w - (g * l)$\n",
        "\n",
        "  [More information](https://sebastianraschka.com/faq/docs/sgd-methods.html)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r97xNBbcqrMK"
      },
      "source": [
        "**Question 26: Create a function that if passed arguments two arguments ```[1,2,3,4]``` and 'abcd', returns ```[(1,'a'),(2,'b'),(3,'c'),(4,'d')]```. What is special about that output data structure?**\n",
        "\n",
        "What is interesting about this data strucuture is that it perfectly embodies the separation between predictor and predictie variables for each data instance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGRoU5APrwNy",
        "outputId": "17226a68-8f29-4131-887e-6b43ee64c7e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "numbers = [1, 2, 3, 4]\n",
        "letters = ['a', 'b', 'c', 'd']\n",
        "\n",
        "list(zip(numbers, letters))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 'a'), (2, 'b'), (3, 'c'), (4, 'd')]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhmvjlhfsPdK"
      },
      "source": [
        "**Question 27: What does view do in PyTorch?**\n",
        "\n",
        "It allows to \"reshape\" a tensor without modyfing the underlying structure."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZzGJjMEtJMo"
      },
      "source": [
        "**Question 28: What are the bias parameters in a neural network**\n",
        "\n",
        "Linear activation functions are linear regressions. Therefore the bias parameters (also known as the intercept) is a key element in the linear regression definition that adds a constant value to the function: $y = w*x + b$, where $b$ is the bias."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnQbPi4st1sa"
      },
      "source": [
        "**Question 29: What does the ```@``` operator do in PyTorch?**\n",
        "\n",
        "Matrix multiplication."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4zJTLs_vqnj",
        "outputId": "1d7ecaf9-9c0e-4b1f-b93e-819b50e9657f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "mat1 = torch.randn(2, 3)\n",
        "mat2 = torch.randn(3, 2)\n",
        "\n",
        "print(torch.mm(mat1, mat2))\n",
        "print(mat1 @ mat2)\n",
        "print(torch.matmul(mat1, mat2))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.1905,  0.2841],\n",
            "        [ 1.3964, -0.0828]])\n",
            "tensor([[-0.1905,  0.2841],\n",
            "        [ 1.3964, -0.0828]])\n",
            "tensor([[-0.1905,  0.2841],\n",
            "        [ 1.3964, -0.0828]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFLs2At4wWR8"
      },
      "source": [
        "**Question 30: What does the ```backward()``` method do?**\n",
        "\n",
        "It computes the gradients of current tensor. It corresponds to a part of the backward pass in backpropagation (the other part is the update of the weights using the newly calculated gradient values)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntr8vVEcxCDR"
      },
      "source": [
        "**Question 31: Why do we have to zero the gradients?**\n",
        "\n",
        "Because PyTorch accumulates the gradients on subsequent backward passes. So, for every mini-batch we need to explicitly set the gradients to zero before starting to do backpropragation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmX5JGZ3y9DC"
      },
      "source": [
        "**Question 32: What information do we have to pass to ```Learner```?**\n",
        "\n",
        "* A ```DataLoaders``` object with the train ```DataLoader``` and the validation ```DataLoader```.\n",
        "* The model.\n",
        "* The optimizer.\n",
        "* The loss function.\n",
        "* The metric\n",
        "\n",
        "[Learner documentation in the FastAI API](https://docs.fast.ai/learner.html#Learner)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WlIOP56z_XS"
      },
      "source": [
        "**Question 33: Show Python or pseudocode for the basic steps of a training loop**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xIx9Ij50eHZ",
        "outputId": "59c477a2-ae93-48ae-a855-7451f4b0067a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        }
      },
      "source": [
        "import graphviz\n",
        "\n",
        "def gv(s): return graphviz.Source('digraph G{ rankdir=\"LR\"' + s + '; }')\n",
        "\n",
        "gv('''\n",
        "data->model->loss\n",
        "model->metric\n",
        "metric->model[label=validate]\n",
        "loss->model[label=update]\n",
        "''')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.files.Source at 0x7fc18c33c050>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: G Pages: 1 -->\n<svg width=\"316pt\" height=\"102pt\"\n viewBox=\"0.00 0.00 316.49 102.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 98)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-98 312.4879,-98 312.4879,4 -4,4\"/>\n<!-- data -->\n<g id=\"node1\" class=\"node\">\n<title>data</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"27\" cy=\"-47\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-43.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">data</text>\n</g>\n<!-- model -->\n<g id=\"node2\" class=\"node\">\n<title>model</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"125.4469\" cy=\"-47\" rx=\"34.394\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"125.4469\" y=\"-43.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">model</text>\n</g>\n<!-- data&#45;&gt;model -->\n<g id=\"edge1\" class=\"edge\">\n<title>data&#45;&gt;model</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M54.1617,-47C62.4319,-47 71.7498,-47 80.8544,-47\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"80.9761,-50.5001 90.9761,-47 80.9761,-43.5001 80.9761,-50.5001\"/>\n</g>\n<!-- loss -->\n<g id=\"node3\" class=\"node\">\n<title>loss</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"274.6909\" cy=\"-76\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"274.6909\" y=\"-72.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">loss</text>\n</g>\n<!-- model&#45;&gt;loss -->\n<g id=\"edge2\" class=\"edge\">\n<title>model&#45;&gt;loss</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M144.1043,-62.3628C153.6009,-69.1959 165.6969,-76.482 177.8939,-80 197.4381,-85.6372 220.119,-85.0555 238.6111,-82.8726\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"239.2558,-86.3169 248.6826,-81.4812 238.2977,-79.3828 239.2558,-86.3169\"/>\n</g>\n<!-- metric -->\n<g id=\"node4\" class=\"node\">\n<title>metric</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"274.6909\" cy=\"-18\" rx=\"33.5952\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"274.6909\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">metric</text>\n</g>\n<!-- model&#45;&gt;metric -->\n<g id=\"edge3\" class=\"edge\">\n<title>model&#45;&gt;metric</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M157.8307,-40.7074C179.7863,-36.4412 209.0158,-30.7615 232.7492,-26.1498\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"233.7343,-29.5239 242.8831,-24.1807 232.3991,-22.6525 233.7343,-29.5239\"/>\n</g>\n<!-- loss&#45;&gt;model -->\n<g id=\"edge5\" class=\"edge\">\n<title>loss&#45;&gt;model</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M250.1034,-68.1206C241.5554,-65.5843 231.8627,-62.9331 222.8939,-61 205.5986,-57.2723 186.3572,-54.2702 169.5714,-52.0163\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"169.8431,-48.5224 159.4765,-50.7099 168.9446,-55.4645 169.8431,-48.5224\"/>\n<text text-anchor=\"middle\" x=\"200.3939\" y=\"-64.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">update</text>\n</g>\n<!-- metric&#45;&gt;model -->\n<g id=\"edge4\" class=\"edge\">\n<title>metric&#45;&gt;model</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M244.7849,-9.1594C225.3011,-4.8605 199.568,-1.9734 177.8939,-9 167.7861,-12.2769 157.994,-18.3126 149.6619,-24.6238\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"147.4331,-21.9249 141.8588,-30.9348 151.8351,-27.3676 147.4331,-21.9249\"/>\n<text text-anchor=\"middle\" x=\"200.3939\" y=\"-12.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">validate</text>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srRsFprW2bAI"
      },
      "source": [
        "**Question 34: What is ReLU? Draw a plot of it for values from -2 to +2**\n",
        "\n",
        "ReLU stands for \"Regularized Linear Unit\". It is a non-linear activation function that is used instead of the sigmoid or tanh functions due to to its simplicity and speed of computation.\n",
        "\n",
        "It assigns 0 to negative values and maintains positive values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyVNSED55T93",
        "outputId": "6d2053ca-491b-4f8c-f575-50c1488c7226",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        }
      },
      "source": [
        "from fastbook import *\n",
        "\n",
        "plot_function(F.relu)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/fastbook/__init__.py:74: UserWarning: Not providing a value for linspace's steps is deprecated and will throw a runtime error in a future release. This warning will appear only once per process. (Triggered internally at  /pytorch/aten/src/ATen/native/RangeFactories.cpp:25.)\n",
            "  x = torch.linspace(min,max)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQPb6TAh6ejP"
      },
      "source": [
        "**Question 35: What is an activation function?**\n",
        "\n",
        "It defines how the linear output of a layer is transformed. The majority of activation functions are non-linear to give more flexibility to the neural network model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnZzMAwB7Qua"
      },
      "source": [
        "**Question 36: What is the difference between ```F.relu``` and ```nn.ReLU```?**\n",
        "\n",
        "F. relu is a Python function and nn.Relu is a Python class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2hsw__a7kV_"
      },
      "source": [
        "**Question 37: The universal approximation theorem shows that any function can be approximated as closely as needed using just one nonlinearity. So why do we normally use more?**\n",
        "\n",
        "Because using a single layer is much more complex to train and while it is theoretically possible, in practive we have observed better results with multiple smaller layers."
      ]
    }
  ]
}