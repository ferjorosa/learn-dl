{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPc53RDgPLg8dZLqbGax1Ba",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ferjorosa/learn-fastai/blob/main/mnist_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuhrF6LdzSmS"
      },
      "source": [
        "# MNIST example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-INgLlAWzYpC"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4q9s78VdcjKW",
        "outputId": "6eafa4d3-d337-452d-8c37-2fbc49534f32"
      },
      "source": [
        "#hide (Google Colab)\n",
        "!pip install fastai --upgrade -q\n",
        "import fastai\n",
        "print(fastai.__version__)\n",
        "\n",
        "!pip install -Uqq fastbook\n",
        "import fastbook\n",
        "fastbook.setup_book()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 189 kB 4.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.4 MB/s \n",
            "\u001b[?25h2.5.3\n",
            "\u001b[K     |████████████████████████████████| 720 kB 4.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 46 kB 4.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 30.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 51 kB 320 kB/s \n",
            "\u001b[?25hMounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2R3mXXIgdNPf"
      },
      "source": [
        "#hide\n",
        "from fastai.vision.all import *\n",
        "from fastbook import *\n",
        "\n",
        "matplotlib.rc('image', cmap='Greys')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcZNNzkjzb6k"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYXcTIyhcs3p",
        "outputId": "6a25d546-7d05-401d-e11b-ae661e706332",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "source": [
        "path = untar_data(URLs.MNIST)\n",
        "\n",
        "zeros = (path/\"training\"/\"0\").ls().sorted()\n",
        "ones = (path/\"training\"/\"1\").ls().sorted()\n",
        "twos = (path/\"training\"/\"2\").ls().sorted()\n",
        "threes = (path/\"training\"/\"3\").ls().sorted()\n",
        "fours = (path/\"training\"/\"4\").ls().sorted()\n",
        "fives = (path/\"training\"/\"5\").ls().sorted()\n",
        "sixes = (path/\"training\"/\"6\").ls().sorted()\n",
        "sevens = (path/\"training\"/\"7\").ls().sorted()\n",
        "eights = (path/\"training\"/\"8\").ls().sorted()\n",
        "nines = (path/\"training\"/\"9\").ls().sorted()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='15687680' class='' max='15683414' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.03% [15687680/15683414 00:02<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ongT38p7eShw"
      },
      "source": [
        "zero_tensors = [tensor(Image.open(o)) for o in zeros]\n",
        "one_tensors = [tensor(Image.open(o)) for o in ones]\n",
        "two_tensors = [tensor(Image.open(o)) for o in twos]\n",
        "three_tensors = [tensor(Image.open(o)) for o in threes]\n",
        "four_tensors = [tensor(Image.open(o)) for o in fours]\n",
        "five_tensors = [tensor(Image.open(o)) for o in fives]\n",
        "six_tensors = [tensor(Image.open(o)) for o in sixes]\n",
        "seven_tensors = [tensor(Image.open(o)) for o in sevens]\n",
        "eight_tensors = [tensor(Image.open(o)) for o in eights]\n",
        "nine_tensors = [tensor(Image.open(o)) for o in nines]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "id": "0bSjyyqkqG4V",
        "outputId": "5ce90f9e-01f3-4f65-8759-378d145a0718"
      },
      "source": [
        "show_image(nine_tensors[2])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fa1b0195b90>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 72x72 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxJYtdh9uIb0",
        "outputId": "aec616be-5a51-42b9-b1fb-84ea33d62f1b"
      },
      "source": [
        "nine_tensors[0].shape[0]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ei9qerj-qiQm",
        "outputId": "99f626b1-c121-4d7a-86aa-5aac711445cd"
      },
      "source": [
        "img_dim = nine_tensors[0].shape[0]**2\n",
        "\n",
        "stacked_zeros = torch.stack(zero_tensors).view(-1, img_dim).float()/255\n",
        "stacked_ones = torch.stack(one_tensors).view(-1, img_dim).float()/255\n",
        "stacked_twos = torch.stack(two_tensors).view(-1, img_dim).float()/255\n",
        "stacked_threes = torch.stack(three_tensors).view(-1, img_dim).float()/255\n",
        "stacked_fours = torch.stack(four_tensors).view(-1, img_dim).float()/255\n",
        "stacked_fives = torch.stack(five_tensors).view(-1, img_dim).float()/255\n",
        "stacked_sixes = torch.stack(six_tensors).view(-1, img_dim).float()/255\n",
        "stacked_sevens = torch.stack(seven_tensors).view(-1, img_dim).float()/255\n",
        "stacked_eights = torch.stack(eight_tensors).view(-1, img_dim).float()/255\n",
        "stacked_nines = torch.stack(nine_tensors).view(-1, img_dim).float()/255\n",
        "\n",
        "stacked_eights.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5851, 784])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4Pvld8_sWck",
        "outputId": "a78ef1cb-03af-429b-a7f0-f628c5123a41"
      },
      "source": [
        "data_x =torch.cat([stacked_zeros, \n",
        "                   stacked_ones,\n",
        "                   stacked_twos, \n",
        "                   stacked_threes,\n",
        "                   stacked_fours,\n",
        "                   stacked_fives,\n",
        "                   stacked_sixes,\n",
        "                   stacked_sevens,\n",
        "                   stacked_eights,\n",
        "                   stacked_nines])\n",
        "\n",
        "data_y = torch.cat([torch.tensor([0] * len(stacked_zeros)), \n",
        "                    torch.tensor([1] * len(stacked_ones)),\n",
        "                    torch.tensor([2] * len(stacked_twos)),\n",
        "                    torch.tensor([3] * len(stacked_threes)),\n",
        "                    torch.tensor([4] * len(stacked_fours)),\n",
        "                    torch.tensor([5] * len(stacked_fives)),\n",
        "                    torch.tensor([6] * len(stacked_sixes)),\n",
        "                    torch.tensor([7] * len(stacked_sevens)),\n",
        "                    torch.tensor([8] * len(stacked_eights)),\n",
        "                    torch.tensor([9] * len(stacked_nines))])#.unsqueeze(1)\n",
        "\n",
        "(data_x.shape, data_y.shape)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([60000, 784]), torch.Size([60000]))"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IBfijk5_2Nl"
      },
      "source": [
        "**Note on unsqueeze(1).** In the \"basic_mnist_example\", we used a dimension of [60000, 1] that was obtained by using unsqueeze. However, when using softmax, this has resulted in issues..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1WojQDSzP1D"
      },
      "source": [
        "#### Divide training data into \"train\" and \"validation\"\n",
        "\n",
        "In order to do it we are going to sample (without replacement) a number of integer values from 0 to 60000. Then select those data instances as the validation data, and the rest of data instances as the training data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ad_XnY5wBWE",
        "outputId": "aa63518e-f7b9-4314-8ca0-f2666edc2f11"
      },
      "source": [
        "n_data = data_x.shape[0]\n",
        "n_valid = 5000\n",
        "\n",
        "valid_indices = np.random.choice(n_data, n_val, replace=False)\n",
        "valid_mask = np.zeros(n_data, bool)\n",
        "valid_mask[valid_indices] = True\n",
        "\n",
        "valid_data_x = data_x[valid_mask]\n",
        "valid_data_y = data_y[valid_mask]\n",
        "\n",
        "train_data_x = data_x[~valid_mask]\n",
        "train_data_y = data_y[~valid_mask]\n",
        "\n",
        "print(train_data_x.shape, valid_data_x.shape)\n",
        "print(train_data_y.shape, valid_data_y.shape)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([55000, 784]) torch.Size([5000, 784])\n",
            "torch.Size([55000]) torch.Size([5000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0hED2zb1u1H"
      },
      "source": [
        "#### Create the DataLoaders object that will be used in training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QuNO_Ys1G3e"
      },
      "source": [
        "train_dset = list(zip(train_data_x, train_data_y))\n",
        "valid_dset = list(zip(valid_data_x, valid_data_y))"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXblim3405Kg",
        "outputId": "011e928a-e5c6-40b9-c5c9-6b0d8018ff12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_dl = DataLoader(train_dset, batch_size=256, shuffle=True)\n",
        "xb, yb = first(train_dl)\n",
        "print(xb.shape, yb.shape)\n",
        "\n",
        "valid_dl = DataLoader(valid_dset, batch_size=256, shuffle=True)\n",
        "xb, yb = first(valid_dl)\n",
        "print(xb.shape, yb.shape)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([256, 784]) torch.Size([256])\n",
            "torch.Size([256, 784]) torch.Size([256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMWkTFJYRXWY"
      },
      "source": [
        "## Model training\n",
        "\n",
        "#### Cross-entropy loss\n",
        "\n",
        "When using the cross-entropy loss, it is not necessary that we establish a softmax layer in the model because it will be implicitly called by Pytorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CniehbmLxyz",
        "outputId": "316a4a88-d31f-4ad1-9d9e-4668a7d86514",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        }
      },
      "source": [
        "from fastai.metrics import accuracy\n",
        "\n",
        "lr = 1e-3\n",
        "dls = DataLoaders(train_dl, valid_dl)\n",
        "\n",
        "simple_net = nn.Sequential(\n",
        "    nn.Linear(28*28,30),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(30,10)\n",
        "    )\n",
        "\n",
        "learner = Learner(dls, simple_net, opt_func=SGD, loss_func=nn.CrossEntropyLoss(), metrics=accuracy)\n",
        "learner.fit(5, lr)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.268242</td>\n",
              "      <td>2.262134</td>\n",
              "      <td>0.127600</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.239922</td>\n",
              "      <td>2.231617</td>\n",
              "      <td>0.221800</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.206672</td>\n",
              "      <td>2.197941</td>\n",
              "      <td>0.348200</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.171254</td>\n",
              "      <td>2.160097</td>\n",
              "      <td>0.433800</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2.130621</td>\n",
              "      <td>2.119002</td>\n",
              "      <td>0.489600</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhaUhPn1BTnd"
      },
      "source": [
        "#### Negative log-likelihood loss\n",
        "\n",
        "When using the NLL loss, it is necessarty that we establish a LogSoftmax layer at the end of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGih0x4lAjBl",
        "outputId": "620e410b-9fe4-4ff0-8e24-630cb554eb0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "from fastai.metrics import accuracy\n",
        "\n",
        "lr = 1e-3\n",
        "dls = DataLoaders(train_dl, valid_dl)\n",
        "\n",
        "simple_net = nn.Sequential(\n",
        "    nn.Linear(28*28,30),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(30,10),\n",
        "    nn.LogSoftmax(dim=1)\n",
        "    )\n",
        "\n",
        "learner = Learner(dls, simple_net, opt_func=SGD, loss_func=nn.NLLLoss(), metrics=accuracy)\n",
        "learner.fit(5, lr)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.285935</td>\n",
              "      <td>2.279514</td>\n",
              "      <td>0.205400</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.250702</td>\n",
              "      <td>2.243002</td>\n",
              "      <td>0.274600</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.213490</td>\n",
              "      <td>2.204628</td>\n",
              "      <td>0.336400</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.173173</td>\n",
              "      <td>2.163038</td>\n",
              "      <td>0.437800</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2.130165</td>\n",
              "      <td>2.118511</td>\n",
              "      <td>0.492600</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2.084659</td>\n",
              "      <td>2.071405</td>\n",
              "      <td>0.520200</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>2.036400</td>\n",
              "      <td>2.021930</td>\n",
              "      <td>0.537600</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.982996</td>\n",
              "      <td>1.970279</td>\n",
              "      <td>0.554400</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.930216</td>\n",
              "      <td>1.916448</td>\n",
              "      <td>0.568400</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.876268</td>\n",
              "      <td>1.860669</td>\n",
              "      <td>0.584600</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}