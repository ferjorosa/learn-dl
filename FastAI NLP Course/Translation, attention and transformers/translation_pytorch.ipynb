{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOvnoJdPcKS58gfpeCZSOYb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ferjorosa/learn-pytorch/blob/main/FastAI%20NLP%20Course/Translation%2C%20attention%20and%20transformers/translation_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Translation with a Sequence to Sequence Network and Attention\n",
        "\n",
        "In this project we will be teaching a neural network to translate from French to English.\n",
        "\n",
        "```\n",
        "[KEY: > input, = target, < output]\n",
        "\n",
        "> il est en train de peindre un tableau .\n",
        "= he is painting a picture .\n",
        "< he is painting a picture .\n",
        "\n",
        "> pourquoi ne pas essayer ce vin delicieux ?\n",
        "= why not try that delicious wine ?\n",
        "< why not try that delicious wine ?\n",
        "\n",
        "> elle n est pas poete mais romanciere .\n",
        "= she is not a poet but a novelist .\n",
        "< she not not a poet but a novelist .\n",
        "\n",
        "> vous etes trop maigre .\n",
        "= you re too skinny .\n",
        "< you re all alone .\n",
        "```\n",
        "\n",
        "This is made possible by the simple but powerful idea of the <a href=\"https://arxiv.org/abs/1409.3215\">sequence to sequence network</a>, in which two recurrent neural networks work together to transform one sequence to another. An encoder network condenses an input sequence into a vector, and a decoder network unfolds that vector into a new sequence.\n",
        "\n",
        "<img src=\"images/sequence_to_sequence_example.png\">\n",
        "\n",
        "To improve upon this model we’ll use an <a href=\"https://arxiv.org/abs/1409.0473\">attention mechanism</a>, which lets the decoder learn to focus over a specific range of the input sequence."
      ],
      "metadata": {
        "id": "B_E5sD3Ff09T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pD8zsxNcfzLB",
        "outputId": "187aceed-e536-4722-b13b-311f99beaee0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-28 17:44:03--  https://raw.githubusercontent.com/ferjorosa/learn-pytorch/main/FastAI%20NLP%20Course/Translation%2C%20attention%20and%20transformers/data_translation/eng-fra.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9541158 (9.1M) [text/plain]\n",
            "Saving to: ‘raw.githubusercontent.com/eng-fra.txt’\n",
            "\n",
            "raw.githubuserconte 100%[===================>]   9.10M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2022-03-28 17:44:04 (138 MB/s) - ‘raw.githubusercontent.com/eng-fra.txt’ saved [9541158/9541158]\n",
            "\n",
            "FINISHED --2022-03-28 17:44:04--\n",
            "Total wall clock time: 0.7s\n",
            "Downloaded: 1 files, 9.1M in 0.07s (138 MB/s)\n"
          ]
        }
      ],
      "source": [
        "#Only on Google Colab\n",
        "\n",
        "URL = \"https://raw.githubusercontent.com/ferjorosa/learn-pytorch/main/FastAI%20NLP%20Course/Translation%2C%20attention%20and%20transformers/data_translation\"\n",
        "\n",
        "!wget -r --no-parent --cut-dirs=7 {URL}/eng-fra.txt\n",
        "\n",
        "\n",
        "!mv raw.githubusercontent.com data_translation\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "LDrEmeweoOHK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}