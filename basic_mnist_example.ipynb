{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOENPf/6uGi/96gUm+iZmu4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ferjorosa/learn-fastai/blob/main/basic_mnist_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1xAial2amrd"
      },
      "source": [
        "# **Basic MNIST example**\n",
        "\n",
        "The objective of this notebook is to simply put my notes and examples of the MNIST example of Chapter 4 from the Fast AI book\n",
        "\n",
        "**Note:** Im not completely sure that I have perfectly followed the implementation of Fast AI book because it dones not work as good. Howver, after several tests I have come to the conclusion that the SGD implementation from Pytorch may be the main difference (although i cannot assure that my validation implementation is fully correct)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pObvZ9p-aYj"
      },
      "source": [
        "### Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dM7BtI9vahp9",
        "outputId": "a69d9fc7-e731-4e94-db1c-8a61f98aabd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#hide (Google Colab)\n",
        "!pip install fastai --upgrade -q\n",
        "import fastai\n",
        "print(fastai.__version__)\n",
        "\n",
        "!pip install -Uqq fastbook\n",
        "import fastbook\n",
        "fastbook.setup_book()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFKKBVgDalMd"
      },
      "source": [
        "#hide\n",
        "from fastai.vision.all import *\n",
        "from fastbook import *\n",
        "\n",
        "matplotlib.rc('image', cmap='Greys')"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHXWv_3N-mfK"
      },
      "source": [
        "### **Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYhQ09YLcM__",
        "outputId": "5ae6ee83-40de-4507-dc42-34abb98e139c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "path = untar_data(URLs.MNIST_SAMPLE)\n",
        "threes = (path/'train'/'3').ls().sorted()\n",
        "sevens = (path/'train'/'7').ls().sorted()\n",
        "threes"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#6131) [Path('/root/.fastai/data/mnist_sample/train/3/10.png'),Path('/root/.fastai/data/mnist_sample/train/3/10000.png'),Path('/root/.fastai/data/mnist_sample/train/3/10011.png'),Path('/root/.fastai/data/mnist_sample/train/3/10031.png'),Path('/root/.fastai/data/mnist_sample/train/3/10034.png'),Path('/root/.fastai/data/mnist_sample/train/3/10042.png'),Path('/root/.fastai/data/mnist_sample/train/3/10052.png'),Path('/root/.fastai/data/mnist_sample/train/3/1007.png'),Path('/root/.fastai/data/mnist_sample/train/3/10074.png'),Path('/root/.fastai/data/mnist_sample/train/3/10091.png')...]"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUnRQ1Cgcfqe",
        "outputId": "f6ccee73-4ced-433c-dad9-5a971feebbf1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "seven_tensors = [tensor(Image.open(o)) for o in sevens]\n",
        "three_tensors = [tensor(Image.open(o)) for o in threes]\n",
        "len(three_tensors),len(seven_tensors)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6131, 6265)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNtJwGr_cZ9G",
        "outputId": "51a982ca-d613-4cc9-e6ee-f78ddb06c9c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "stacked_sevens = torch.stack(seven_tensors).float()/255\n",
        "stacked_threes = torch.stack(three_tensors).float()/255\n",
        "stacked_threes.shape"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6131, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZOkO4Q2dUP2",
        "outputId": "a1eb65d1-64d9-4a3f-86cd-dcfe0f0e3cc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "valid_3_tens = torch.stack([tensor(Image.open(o)) \n",
        "                            for o in (path/'valid'/'3').ls()])\n",
        "valid_3_tens = valid_3_tens.float()/255\n",
        "valid_7_tens = torch.stack([tensor(Image.open(o)) \n",
        "                            for o in (path/'valid'/'7').ls()])\n",
        "valid_7_tens = valid_7_tens.float()/255\n",
        "valid_3_tens.shape,valid_7_tens.shape"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1010, 28, 28]), torch.Size([1028, 28, 28]))"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4kLrBhq--fh"
      },
      "source": [
        "### **Single-batch gradient descent**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oidziwAcp_P",
        "outputId": "41a73be4-440d-41d6-ef5a-3439ee0017c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "gv('''\n",
        "init->predict->loss->gradient->step->stop\n",
        "step->predict[label=repeat]\n",
        "''')"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.files.Source at 0x7f7f9dc672d0>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: G Pages: 1 -->\n<svg width=\"597pt\" height=\"78pt\"\n viewBox=\"0.00 0.00 596.69 78.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 74)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-74 592.6863,-74 592.6863,4 -4,4\"/>\n<!-- init -->\n<g id=\"node1\" class=\"node\">\n<title>init</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"27\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">init</text>\n</g>\n<!-- predict -->\n<g id=\"node2\" class=\"node\">\n<title>predict</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"127.3968\" cy=\"-18\" rx=\"36.2938\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"127.3968\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">predict</text>\n</g>\n<!-- init&#45;&gt;predict -->\n<g id=\"edge1\" class=\"edge\">\n<title>init&#45;&gt;predict</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M54.1688,-18C62.3543,-18 71.5827,-18 80.6596,-18\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"80.7795,-21.5001 90.7795,-18 80.7795,-14.5001 80.7795,-21.5001\"/>\n</g>\n<!-- loss -->\n<g id=\"node3\" class=\"node\">\n<title>loss</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"227.7935\" cy=\"-52\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"227.7935\" y=\"-48.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">loss</text>\n</g>\n<!-- predict&#45;&gt;loss -->\n<g id=\"edge2\" class=\"edge\">\n<title>predict&#45;&gt;loss</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M157.5191,-28.2011C168.9806,-32.0826 182.1139,-36.5303 193.9014,-40.5222\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"192.8259,-43.8532 203.4202,-43.7458 195.0713,-37.2231 192.8259,-43.8532\"/>\n</g>\n<!-- gradient -->\n<g id=\"node4\" class=\"node\">\n<title>gradient</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"365.7399\" cy=\"-52\" rx=\"40.8928\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"365.7399\" y=\"-48.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gradient</text>\n</g>\n<!-- loss&#45;&gt;gradient -->\n<g id=\"edge3\" class=\"edge\">\n<title>loss&#45;&gt;gradient</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M255.0473,-52C272.0415,-52 294.4481,-52 314.6545,-52\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"314.671,-55.5001 324.671,-52 314.671,-48.5001 314.671,-55.5001\"/>\n</g>\n<!-- step -->\n<g id=\"node5\" class=\"node\">\n<title>step</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"470.6863\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"470.6863\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">step</text>\n</g>\n<!-- gradient&#45;&gt;step -->\n<g id=\"edge4\" class=\"edge\">\n<title>gradient&#45;&gt;step</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M398.9456,-41.2422C410.9558,-37.3512 424.5297,-32.9536 436.6132,-29.0388\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"437.9112,-32.2975 446.3457,-25.8857 435.7537,-25.6382 437.9112,-32.2975\"/>\n</g>\n<!-- step&#45;&gt;predict -->\n<g id=\"edge6\" class=\"edge\">\n<title>step&#45;&gt;predict</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M443.4266,-18C384.9297,-18 246.7861,-18 174.0495,-18\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"173.8098,-14.5001 163.8098,-18 173.8097,-21.5001 173.8098,-14.5001\"/>\n<text text-anchor=\"middle\" x=\"289.7935\" y=\"-21.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">repeat</text>\n</g>\n<!-- stop -->\n<g id=\"node6\" class=\"node\">\n<title>stop</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"561.6863\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"561.6863\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">stop</text>\n</g>\n<!-- step&#45;&gt;stop -->\n<g id=\"edge5\" class=\"edge\">\n<title>step&#45;&gt;stop</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M497.9893,-18C506.2676,-18 515.508,-18 524.3268,-18\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"524.4026,-21.5001 534.4025,-18 524.4025,-14.5001 524.4026,-21.5001\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3u83vqEcrcP",
        "outputId": "112357c9-511e-4cd6-9714-2eac30b3bb4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_x =torch.cat([stacked_threes, stacked_sevens]).view(-1, 28*28)\n",
        "train_y = tensor([0] * len(stacked_threes) + [1] *len(stacked_sevens)).unsqueeze(1)\n",
        "(train_x.shape, train_y.shape)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([12396, 784]), torch.Size([12396, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqdJprAIdCh-",
        "outputId": "93c6ecbe-a9e9-4b41-89d6-3995c4b6918e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "valid_x = torch.cat([valid_3_tens, valid_7_tens]).view(-1,28*28)\n",
        "valid_y = tensor([0] * len(valid_3_tens) + [1] * len(valid_7_tens)).unsqueeze(1)\n",
        "(valid_x.shape, valid_y.shape)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([2038, 784]), torch.Size([2038, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZHBEUhIdaTP"
      },
      "source": [
        "def init_params(size, std=1.0): return (torch.randn(size) * std).requires_grad_()\n",
        "\n",
        "def mnist_loss(predictions, targets): \n",
        "  predictions = predictions.sigmoid()\n",
        "  return torch.where(targets==1, 1-predictions, predictions).mean()\n",
        "\n",
        "def linear3(x, w): return x@w + intercept\n",
        "  \n",
        "def predict(x, w):\n",
        "  linear_predictions = model(x, w)\n",
        "  predictions = linear_predictions.sigmoid()\n",
        "  return torch.where(predictions > 0.5, 1, 0)\n",
        "\n",
        "def validate(valid_x, w, valid_y):\n",
        "  binary_preds = predict(valid_x, w)\n",
        "  return (binary_preds == valid_y).count_nonzero() / valid_y.shape[0]\n",
        "\n",
        "def epoch1(x, y, w, valid_x, valid_y, prt=True):\n",
        "  pred = model(x, w)\n",
        "  loss = mnist_loss(pred, y)\n",
        "  loss.backward()\n",
        "  if prt: print(\"Loss: \" + str(loss))\n",
        "  accuracy = validate(valid_x, w, valid_y)\n",
        "  if prt: print(\"Validation accuracy: \" + str(accuracy))\n",
        "  w.data -= w.grad * lr\n",
        "\n",
        "w = init_params((784, 1))\n",
        "lr = 1e-3\n",
        "model = linear3\n",
        "weights = init_params((28*28,1))\n",
        "intercept = init_params(1)"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyom4n7idfv3",
        "outputId": "0b62c3ef-dd47-446b-f33a-fd4250b7b406",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "epoch1(train_x, train_y, w, valid_x, valid_y)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: tensor(0.3155, grad_fn=<MeanBackward0>)\n",
            "Validation accuracy: tensor(0.7090)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3O6JAiJpdicu",
        "outputId": "378585e5-3842-4cc7-c536-f78b8d75bf03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "n_epochs = 5\n",
        "for i in range (1, n_epochs):\n",
        "  epoch1(train_x, train_y, w, valid_x, valid_y)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: tensor(0.3151, grad_fn=<MeanBackward0>)\n",
            "Validation accuracy: tensor(0.7100)\n",
            "Loss: tensor(0.3149, grad_fn=<MeanBackward0>)\n",
            "Validation accuracy: tensor(0.7100)\n",
            "Loss: tensor(0.3147, grad_fn=<MeanBackward0>)\n",
            "Validation accuracy: tensor(0.7100)\n",
            "Loss: tensor(0.3145, grad_fn=<MeanBackward0>)\n",
            "Validation accuracy: tensor(0.7100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEprVnl6rI5M"
      },
      "source": [
        "### **Stochastic gradient descent**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHcA3aP6_gq5"
      },
      "source": [
        "When working with gradient descent it may be interesting to consider only a hadful of batches at each iteration. We can do this with Fast AI in a ver simple\n",
        "manner with the *DataLoader* class.\n",
        "\n",
        "In the following implementation, each epoch considers all of the data. However, **each epoch updates the parameters multiple times** by considering all of the data in batch form in random order. \n",
        "\n",
        "**Note on theory:** I am not completely sure this is the traditional way of doing SGD, but it was the intuition I obtained from reading the AI book\n",
        "\n",
        "**Note on speed:** Previous implementation is much faster. I suppose due to the absence of the multiple for loops that are here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KUmlZ9tnwXD"
      },
      "source": [
        "train_dset = list(zip(train_x, train_y))\n",
        "valid_dset = list(zip(train_x, train_y))"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mv3GAJ6VrTyi",
        "outputId": "8196bc93-a30d-4f05-95d3-e62917c8f944",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_dl = DataLoader(train_dset, batch_size=256, shuffle=True)\n",
        "xb, yb = first(train_dl)\n",
        "print(xb.shape, yb.shape)\n",
        "\n",
        "valid_dl = DataLoader(valid_dset, batch_size=256, shuffle=True)\n",
        "xb, yb = first(valid_dl)\n",
        "print(xb.shape, yb.shape)"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([256, 784]) torch.Size([256, 1])\n",
            "torch.Size([256, 784]) torch.Size([256, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzuzDkHdtYHj"
      },
      "source": [
        "class LinearModel:\n",
        "\n",
        "  def __init__(self, intercept, weights):\n",
        "    self.intercept = intercept\n",
        "    self.weights = weights\n",
        "    self.params = (intercept, weights)\n",
        "\n",
        "  def predict(self, data):\n",
        "    return data@self.weights + self.intercept\n",
        "\n",
        "\n",
        "def mnist_loss(predictions, targets): \n",
        "  predictions = predictions.sigmoid()\n",
        "  return torch.where(targets==1, 1-predictions, predictions).mean()\n",
        "\n",
        "def calc_grad(xb, yb, model, prt=True):\n",
        "  pred = model.predict(xb)\n",
        "  loss = mnist_loss(pred, yb)\n",
        "  loss.backward()\n",
        "  if prt: print(\"Loss: \" + str(loss))\n",
        "\n",
        "def train_epoch(train_dl, model, lr, prt=True):\n",
        "  for xb, yb in train_dl: # Iterates over batches, not individual instances\n",
        "    calc_grad(xb, yb, model, prt)\n",
        "    for p in model.params:\n",
        "      p.data -= p.grad * lr\n",
        "      p.grad.zero_() # See page 172, last paragraph\n",
        "  \n",
        "def hard_predict_mnist(xb, model):\n",
        "  linear_predictions = model.predict(xb)\n",
        "  predictions = linear_predictions.sigmoid()\n",
        "  return torch.where(predictions > 0.5, 1, 0)\n",
        "\n",
        "def validate_epoch(valid_dl, model):\n",
        "  batch_accs = [(hard_predict_mnist(valid_xb, model) == valid_yb).count_nonzero() \n",
        "                / valid_yb.shape[0] for valid_xb, valid_yb in valid_dl]\n",
        "  return torch.FloatTensor(batch_accs).mean()"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Us5COdWvl5c"
      },
      "source": [
        "# Small example just to see what was happening under the hood\n",
        "# xb and yb are now batches, not individual data instances\n",
        "\n",
        "# l = []\n",
        "# for xb, yb in train_dl:\n",
        "#   l.append(xb)\n",
        "# len(l)"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTWUzhmb5r4r",
        "outputId": "f149ee3b-bffe-4092-cdde-693e341a6c95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "weights = init_params((28*28,1))\n",
        "intercept = init_params(1)\n",
        "linear_model = LinearModel(intercept, weights)\n",
        "n_epochs=5 \n",
        "\n",
        "for i in range(1, n_epochs):\n",
        "  train_epoch(train_dl, linear_model, 1e-3, False)\n",
        "  validation_acc = validate_epoch(valid_dl, linear_model)\n",
        "  print(\"Epoch validation accuracy: \" + str(validation_acc))"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch validation accuracy: tensor(0.5799)\n",
            "Epoch validation accuracy: tensor(0.5821)\n",
            "Epoch validation accuracy: tensor(0.5847)\n",
            "Epoch validation accuracy: tensor(0.5883)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkiaUvAk96Xy"
      },
      "source": [
        "### **Creating an optimizer**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jCF9qK0Dt9h"
      },
      "source": [
        "Because stochastic gradient descent is such a general foundation, PyTorch provides some useful classes to make it easier to implement."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1y9ptsdtFJz"
      },
      "source": [
        "class BasicOptim:\n",
        "\n",
        "  def __init__(self, params, lr):\n",
        "    self.params = params\n",
        "    self.lr = lr\n",
        "\n",
        "  def step(self, *args, **kwargs):\n",
        "    for p in self.params:\n",
        "      p.data -= p.grad.data * self.lr\n",
        "  \n",
        "  def zero_grad(self, *args, **kwargs):\n",
        "    for p in self.params:\n",
        "      p.grad = None\n",
        "\n",
        "\n",
        "def mnist_loss(predictions, targets): \n",
        "  predictions = predictions.sigmoid()\n",
        "  return torch.where(targets==1, 1-predictions, predictions).mean()\n",
        "\n",
        "def calc_grad(xb, yb, model, prt=False):\n",
        "  pred = model(xb) # Linear does not have predict\n",
        "  loss = mnist_loss(pred, yb)\n",
        "  loss.backward()\n",
        "  if prt: print(\"Loss: \" + str(loss))\n",
        "\n",
        "def train_epoch(train_dl, model, optimizer):\n",
        "  for xb, yb in train_dl:\n",
        "    calc_grad(xb, yb, model)\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "def hard_predict_mnist(xb, model):\n",
        "  linear_predictions = model(xb) # Linear does not have predict\n",
        "  predictions = linear_predictions.sigmoid()\n",
        "  return torch.where(predictions > 0.5, 1, 0)\n",
        "\n",
        "def validate_epoch(valid_dl, model):\n",
        "  batch_accs = [(hard_predict_mnist(valid_xb, model) == valid_yb).count_nonzero() \n",
        "                / valid_yb.shape[0] for valid_xb, valid_yb in valid_dl]\n",
        "  return torch.FloatTensor(batch_accs).mean()\n",
        "\n",
        "def train_model(train_dl, valid_dl, model, optimizer, epochs):\n",
        "  for i in range(epochs):\n",
        "    train_epoch(train_dl, model, optimizer)\n",
        "    print(validate_epoch(valid_dl, model), end=\"\\n\")\n",
        "\n"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XV_POSrL2QJh",
        "outputId": "883ca7c5-1e6f-4574-816d-7e9ad2bc68f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "linear_model = nn.Linear(28*28, 1) # This creates a single LINEAR activation function with 28*28 input features and a single output feature\n",
        "lr=1e-3\n",
        "optimizer = BasicOptim(linear_model.parameters(), lr)\n",
        "train_model(train_dl, valid_dl, linear_model, optimizer, 5)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.5184)\n",
            "tensor(0.5169)\n",
            "tensor(0.5178)\n",
            "tensor(0.5172)\n",
            "tensor(0.5171)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2NZbqGi4r0r"
      },
      "source": [
        "### **Using SGD optimizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHlLDkFZ4wkh",
        "outputId": "1f6999de-33e8-4dfe-e321-1583e52684d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "linear_model = nn.Linear(28*28, 1)\n",
        "optimizer = SGD(linear_model.parameters(), lr)\n",
        "train_model(train_dl, valid_dl, linear_model, optimizer, 5)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.7529)\n",
            "tensor(0.8412)\n",
            "tensor(0.8886)\n",
            "tensor(0.9158)\n",
            "tensor(0.9308)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjjyI9Fz3aZB"
      },
      "source": [
        "### **Using FastAI**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4KT53wK3qyQ"
      },
      "source": [
        "FastAI provides a *Learner* with a *fit()* function, which we can use instead of our implementation of *train_model()*. To create a *Learner*, we first need to create *DataLoaders*, by passing in our training and validation *DataLoaders*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heuZC9lh3o5R",
        "outputId": "356a160a-7da6-4af4-f4db-5f82d34ec43c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "def batch_accuracy(xb, yb):\n",
        "    preds = xb.sigmoid()\n",
        "    correct = (preds>0.5) == yb\n",
        "    return correct.float().mean()\n",
        "\n",
        "lr=1e-3\n",
        "dls = DataLoaders(train_dl, valid_dl)\n",
        "learn = Learner(dls, nn.Linear(28*28,1), opt_func=SGD,\n",
        "                loss_func=mnist_loss, metrics=batch_accuracy)\n",
        "learn.fit(5, lr)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>batch_accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.498531</td>\n",
              "      <td>0.489559</td>\n",
              "      <td>0.624960</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.483522</td>\n",
              "      <td>0.469087</td>\n",
              "      <td>0.800177</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.466223</td>\n",
              "      <td>0.448957</td>\n",
              "      <td>0.888190</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.447886</td>\n",
              "      <td>0.429413</td>\n",
              "      <td>0.924008</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.429469</td>\n",
              "      <td>0.410635</td>\n",
              "      <td>0.938771</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBDTVUqTBRHo"
      },
      "source": [
        "### **Adding a Nonlinearity**\n",
        "\n",
        "We consider a different model. In this case we are going to consider a small network with 2 layers. The first layer is a linear fuction with 28*28 input features whose activaction function is a ReLU, and the second (and output) layer is a linear function with 30 input features and a single input feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLqPxpVpBv7P",
        "outputId": "d5a0928e-38fd-4a7d-872e-4d90a79c6a94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "simple_net = nn.Sequential(\n",
        "    nn.Linear(28*28,30),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(30,1)\n",
        "    )\n",
        "\n",
        "optimizer = SGD(simple_net.parameters(), lr)\n",
        "train_model(train_dl, valid_dl, simple_net, optimizer, 5)"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.7126)\n",
            "tensor(0.7736)\n",
            "tensor(0.8195)\n",
            "tensor(0.8563)\n",
            "tensor(0.8818)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIHNw1y4EQXH"
      },
      "source": [
        "Using FastAI Learner:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmSyu8zeEUiX",
        "outputId": "cde39428-4338-4305-f9a1-5b6afabe4e6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "learn = Learner(dls, simple_net, opt_func=SGD, loss_func=mnist_loss, metrics=batch_accuracy)\n",
        "learn.fit(5, lr)"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>batch_accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.474099</td>\n",
              "      <td>0.472393</td>\n",
              "      <td>0.899242</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.471260</td>\n",
              "      <td>0.468451</td>\n",
              "      <td>0.914973</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.467843</td>\n",
              "      <td>0.464387</td>\n",
              "      <td>0.924976</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.464004</td>\n",
              "      <td>0.460188</td>\n",
              "      <td>0.933285</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.459921</td>\n",
              "      <td>0.455847</td>\n",
              "      <td>0.939255</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}