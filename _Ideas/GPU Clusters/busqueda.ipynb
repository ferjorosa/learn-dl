{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Info general\n",
    "\n",
    "* *Efficient training:* https://huggingface.co/docs/transformers/en/perf_train_gpu_many\n",
    "* *GPU benchmarks for inference:* https://github.com/XiongjieDai/GPU-Benchmarks-on-LLM-Inference\n",
    "* Informacion general sobre clusters: https://www.run.ai/guides/multi-gpu/gpu-clusters"
   ],
   "id": "8b272c0c988a75f7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Local builds\n",
    "\n",
    "He estado investigando diversas builds y es algo complejo. Si tuviera que empezar\n",
    "seguramente iria por un setup de 2x 4090 / 5090 para la parte de experimentacion\n",
    "y dia a dia.\n",
    "\n",
    "\n",
    "Aqui esta una build que soporta 2x4090 (se puede empezar con 1 y si gusta subir a 2)\n",
    "https://pcpartpicker.com/list/QKJJ7R\n",
    "\n",
    "El precio andaria entre los 3500€ para una GPU y los 5500€ para el mismo setup con 2\n",
    "\n",
    "\n",
    "Aqui esta una pagina con una 4090 barata\n",
    "https://www.ldlc.com/es-es/ficha/PB00533768.html\n",
    "\n",
    "Rango alto del precio con un ordenador completamente preparado por una empresa (Precio US de 9800$):\n",
    "\n",
    "https://shop.lambdalabs.com/gpu-workstations/vector/customize\n",
    "\n",
    "Estuve considerando una build con una a6000 pero me da la sensacion de que no es tan eficiente para el precio que tiene y la performance que ofrece:\n",
    "\n",
    "https://pcpartpicker.com/list/kmQc7R"
   ],
   "id": "10c5f41514437523"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Server builds\n",
    "\n",
    "La \"pagina oficial\" para comprar servidores en españa que he visto es https://www.azken.com/\n",
    "\n",
    "He visto que ofrecen diferentes soluciones para alta computacion pero los precios son sinceramente caros. 4x H100 cuestan sobre 120.000€ (320GB de memoria)\n",
    "\n",
    "La verdad es que si empiezas a meterte en muchas GPUs H100 puede tener sentido investigar setups expecificos de NVidia como\n",
    "\n",
    "https://www.azken.com/es/nvidia-dgx-h100/\n",
    "\n",
    "No lo he investigado, pero esta claro que si empizas a meterte en multiples racks de GPUs interconectadas, deberias mirar como conectarlas de la manera mas eficiente para que no pierdas tiempo de computacion y puedas escalar"
   ],
   "id": "794b23b02a4f4f40"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Rent GPUs\n",
    "\n",
    "Puedes conseguir una o varias H100 por menos de 3$ la hora. Para entrenamientos especificos, tiene sentido. Muchas veces empiezas con pruebas a nivel local y luego empiezas a escalar.\n",
    "\n",
    "https://www.runpod.io/"
   ],
   "id": "2715df3d1df38c6a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Host my GPUs\n",
    "\n",
    "No me queda claro cuanto dinero se gana. Podemos asumir un 50% cut del precio que sale si ofrecemos interruptible price\n",
    "\n",
    "https://vast.ai/hosting"
   ],
   "id": "d9ef197d01d84117"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Elon's big cluster of GPUs\n",
    "\n",
    "Mas que nada para mostrar lo que es un verdadero cluster de gpus\n",
    "\n",
    "https://www.youtube.com/watch?v=Jf8EPSBZU7Y"
   ],
   "id": "ce730c9687cb7f61"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
