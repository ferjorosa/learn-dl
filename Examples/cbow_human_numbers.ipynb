{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNMdzGed2pxicIVLCkp8DpT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ferjorosa/learn-pytorch/blob/main/Examples/cbow_human_numbers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Objective of this notebook:\n",
        "\n",
        "* To implement a simple CBOW model and compare its results in the \"human numbers\" data with those produced by our LSTM and GRU models from chapter 12 in FastAI book.\n",
        "\n",
        "* To better understand the output of nn.Embedding when multiple words are provided. \n",
        "\n",
        "In the data example with a context of size 3, a batch size of 64, and a embedding dimension of 64, we would have the following tensor shapes:\n",
        "\n",
        "```python\n",
        "> inputs.shape\n",
        "torch.Size([64, 3])\n",
        "> x.shape\n",
        "torch.Size([64, 3, 64])\n",
        "> y.shape\n",
        "torch.Size([64, 64])\n",
        "> out.shape\n",
        "torch.Size([64, 30])\n",
        "```"
      ],
      "metadata": {
        "id": "MIMUxbNZ_B93"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRdul-CS15ho",
        "outputId": "208342bb-adcb-4c64-d660-d013a61adede"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 189 kB 4.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 55 kB 3.5 MB/s \n",
            "\u001b[?25h2.5.3\n",
            "\u001b[K     |████████████████████████████████| 720 kB 3.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 13.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 48 kB 4.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 51 kB 269 kB/s \n",
            "\u001b[K     |████████████████████████████████| 558 kB 39.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 130 kB 36.4 MB/s \n",
            "\u001b[?25hMounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "#hide (Google Colab)\n",
        "!pip install fastai --upgrade -q\n",
        "import fastai\n",
        "print(fastai.__version__)\n",
        "\n",
        "!pip install -Uqq fastbook\n",
        "import fastbook\n",
        "fastbook.setup_book()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hide (debugging)\n",
        "!pip install -Uqq ipdb\n",
        "import ipdb\n",
        "%pdb on"
      ],
      "metadata": {
        "id": "7C1lgbpRADmX",
        "outputId": "fbd5097c-82ca-4bfc-86fc-bfedf6f05f85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 792 kB 5.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 380 kB 36.8 MB/s \n",
            "\u001b[?25h  Building wheel for ipdb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you have prompt-toolkit 3.0.28 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.31.1 which is incompatible.\u001b[0m\n",
            "Automatic pdb calling has been turned ON\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from fastbook import *\n",
        "from fastai.text.all import *"
      ],
      "metadata": {
        "id": "y4frPntM5jfv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = untar_data(URLs.HUMAN_NUMBERS)\n",
        "\n",
        "Path.BASE_PATH = path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "bBnX5ye42MwP",
        "outputId": "0a3db664-32e8-452a-aa18-77c1fb516598"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='32768' class='' max='30252' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      108.32% [32768/30252 00:00<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lines = L()\n",
        "with open(path/'train.txt') as f: lines += L(*f.readlines())\n",
        "with open(path/'valid.txt') as f: lines += L(*f.readlines())\n",
        "lines"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zdQIeNI6LNQ",
        "outputId": "a1846b0a-9e99-43af-ecb9-dd81f3d55450"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#9998) ['one \\n','two \\n','three \\n','four \\n','five \\n','six \\n','seven \\n','eight \\n','nine \\n','ten \\n'...]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = ' . '.join([l.strip() for l in lines])\n",
        "tokens = text.split(' ')\n",
        "vocab = L(*tokens).unique()\n",
        "word2idx = {w:i for i,w in enumerate(vocab)}\n",
        "nums = L(word2idx[i] for i in tokens)"
      ],
      "metadata": {
        "id": "FdKFmwuo6NaZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#seqs_raw = L((tokens[i:i+3], tokens[i+3]) for i in range(0,len(tokens)-4,3)) # raw form\n",
        "\n",
        "seqs = L((tensor(nums[i:i+3]), nums[i+3]) for i in range(0,len(nums)-4,3)) # coded-number form\n",
        "seqs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAsjwzwk63ze",
        "outputId": "d6b1f81a-5137-4362-cecf-7b87ac6eb7ab"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#21031) [(tensor([0, 1, 2]), 1),(tensor([1, 3, 1]), 4),(tensor([4, 1, 5]), 1),(tensor([1, 6, 1]), 7),(tensor([7, 1, 8]), 1),(tensor([1, 9, 1]), 10),(tensor([10,  1, 11]), 1),(tensor([ 1, 12,  1]), 13),(tensor([13,  1, 14]), 1),(tensor([ 1, 15,  1]), 16)...]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** `seqs_raw` is not valid because our model expects tensor data and **tensors can only be in numeric form**"
      ],
      "metadata": {
        "id": "5fTk1GSs-o6m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bs = 64\n",
        "cut = int(len(seqs) * 0.8)\n",
        "dls = DataLoaders.from_dsets(seqs[:cut], seqs[cut:], bs=64, shuffle=False) # train, validation"
      ],
      "metadata": {
        "id": "pBxonPFA6rdM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_uHhQndE8dFO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CBOW(Module):\n",
        "\n",
        "  def __init__(self, vsz, nh):\n",
        "    self.i_h = nn.Embedding(vsz, nh)\n",
        "    self.h_o = nn.Linear(nh, vsz)\n",
        "  \n",
        "  def forward(self, inputs):\n",
        "    x = self.i_h(inputs)\n",
        "    y = torch.mean(x, axis=1)\n",
        "    out = self.h_o(y)\n",
        "    #ipdb.set_trace()\n",
        "    return out"
      ],
      "metadata": {
        "id": "QsXIO-Qn7Qy4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn = Learner(dls, CBOW(len(vocab), 64), loss_func=F.cross_entropy, \n",
        "                metrics=accuracy)\n",
        "learn.fit_one_cycle(4, 1e-3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "VRTQTYJG7a9H",
        "outputId": "15ed96b4-807c-446d-f9b0-75899c37aa9c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.732165</td>\n",
              "      <td>2.553152</td>\n",
              "      <td>0.431662</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.133930</td>\n",
              "      <td>2.170956</td>\n",
              "      <td>0.435465</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.984797</td>\n",
              "      <td>2.079117</td>\n",
              "      <td>0.435465</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.940968</td>\n",
              "      <td>2.074865</td>\n",
              "      <td>0.434039</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}