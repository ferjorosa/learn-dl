{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/ferjorosa/learn-fastai/blob/main/basic_mnist_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Basic MNIST example**\n",
        "\n",
        "The objective of this notebook is to simply put my notes and examples of the MNIST example of Chapter 4 from the Fast AI book\n",
        "\n",
        "**Note:** Im not completely sure that I have perfectly followed the implementation of Fast AI book because it dones not work as good. Howver, after several tests I have come to the conclusion that the SGD implementation from Pytorch may be the main difference (although i cannot assure that my validation implementation is fully correct)"
      ],
      "metadata": {
        "id": "Y1xAial2amrd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installation"
      ],
      "metadata": {
        "id": "-pObvZ9p-aYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#hide (Google Colab)\n",
        "!pip install fastai --upgrade -q\n",
        "import fastai\n",
        "print(fastai.__version__)\n",
        "\n",
        "!pip install -Uqq fastbook\n",
        "import fastbook\n",
        "fastbook.setup_book()"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "id": "dM7BtI9vahp9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dbfedc5-c979-4971-d305-ae25f4be9106",
        "gather": {
          "logged": 1651160068233
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#hide\n",
        "from fastai.vision.all import *\n",
        "from fastbook import *\n",
        "\n",
        "matplotlib.rc('image', cmap='Greys')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "zFKKBVgDalMd",
        "gather": {
          "logged": 1651160069105
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Data**"
      ],
      "metadata": {
        "id": "IHXWv_3N-mfK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = untar_data(URLs.MNIST_SAMPLE)\n",
        "threes = (path/'train'/'3').ls().sorted()\n",
        "sevens = (path/'train'/'7').ls().sorted()\n",
        "threes"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "WYhQ09YLcM__",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "7b020564-622f-4be2-89ab-bedcb5328b85",
        "gather": {
          "logged": 1651160069121
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seven_tensors = [tensor(Image.open(o)) for o in sevens]\n",
        "three_tensors = [tensor(Image.open(o)) for o in threes]\n",
        "len(three_tensors),len(seven_tensors)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "JUnRQ1Cgcfqe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a64e7d48-a4e1-4599-9031-7b6c6fae276d",
        "gather": {
          "logged": 1651160069138
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stacked_sevens = torch.stack(seven_tensors).float()/255\n",
        "stacked_threes = torch.stack(three_tensors).float()/255\n",
        "stacked_threes.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "JNtJwGr_cZ9G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e67b78b-34ed-4ee5-e4b1-ebe81b4cdb8b",
        "gather": {
          "logged": 1651160069155
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "valid_3_tens = torch.stack([tensor(Image.open(o)) \n",
        "                            for o in (path/'valid'/'3').ls()])\n",
        "valid_3_tens = valid_3_tens.float()/255\n",
        "valid_7_tens = torch.stack([tensor(Image.open(o)) \n",
        "                            for o in (path/'valid'/'7').ls()])\n",
        "valid_7_tens = valid_7_tens.float()/255\n",
        "valid_3_tens.shape,valid_7_tens.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "kZOkO4Q2dUP2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12a25ae2-94b9-4dec-f2bd-17221ea1586f",
        "gather": {
          "logged": 1651160069172
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Single-batch gradient descent**"
      ],
      "metadata": {
        "id": "G4kLrBhq--fh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gv('''\n",
        "init->predict->loss->gradient->step->stop\n",
        "step->predict[label=repeat]\n",
        "''')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "9oidziwAcp_P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "bc0e0b52-121c-47ce-a222-2cf14c5cb3e4",
        "gather": {
          "logged": 1651160069192
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_x =torch.cat([stacked_threes, stacked_sevens]).view(-1, 28*28)\n",
        "train_y = tensor([0] * len(stacked_threes) + [1] *len(stacked_sevens)).unsqueeze(1)\n",
        "(train_x.shape, train_y.shape)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "U3u83vqEcrcP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0151159-e801-4c7c-dcee-470725b68b6c",
        "gather": {
          "logged": 1651160069209
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "valid_x = torch.cat([valid_3_tens, valid_7_tens]).view(-1,28*28)\n",
        "valid_y = tensor([0] * len(valid_3_tens) + [1] * len(valid_7_tens)).unsqueeze(1)\n",
        "(valid_x.shape, valid_y.shape)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "YqdJprAIdCh-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcef7ab8-0874-41e7-86c4-00d2420578bf",
        "gather": {
          "logged": 1651160069230
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def init_params(size, std=1.0): return (torch.randn(size) * std).requires_grad_()\n",
        "\n",
        "def mnist_loss(predictions, targets): \n",
        "  predictions = predictions.sigmoid()\n",
        "  return torch.where(targets==1, 1-predictions, predictions).mean()\n",
        "\n",
        "def linear3(x, w): return x@w + intercept\n",
        "  \n",
        "def predict(x, w):\n",
        "  linear_predictions = model(x, w)\n",
        "  predictions = linear_predictions.sigmoid()\n",
        "  return torch.where(predictions > 0.5, 1, 0)\n",
        "\n",
        "def validate(valid_x, w, valid_y):\n",
        "  binary_preds = predict(valid_x, w)\n",
        "  return (binary_preds == valid_y).count_nonzero() / valid_y.shape[0]\n",
        "\n",
        "def epoch1(x, y, w, valid_x, valid_y, prt=True):\n",
        "  pred = model(x, w)\n",
        "  loss = mnist_loss(pred, y)\n",
        "  loss.backward()\n",
        "  if prt: print(\"Loss: \" + str(loss))\n",
        "  accuracy = validate(valid_x, w, valid_y)\n",
        "  if prt: print(\"Validation accuracy: \" + str(accuracy))\n",
        "  w.data -= w.grad * lr\n",
        "\n",
        "w = init_params((784, 1))\n",
        "lr = 1e-3\n",
        "model = linear3\n",
        "weights = init_params((28*28,1))\n",
        "intercept = init_params(1)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "1ZHBEUhIdaTP",
        "gather": {
          "logged": 1651160069250
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epoch1(train_x, train_y, w, valid_x, valid_y)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "oyom4n7idfv3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e5c7b79-e7bc-4677-ae32-a50a84609673",
        "gather": {
          "logged": 1651160069269
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 5\n",
        "for i in range (1, n_epochs):\n",
        "  epoch1(train_x, train_y, w, valid_x, valid_y)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "3O6JAiJpdicu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b718cf4a-ac9a-4355-db99-5f62662111bd",
        "gather": {
          "logged": 1651160069289
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Stochastic gradient descent**"
      ],
      "metadata": {
        "id": "UEprVnl6rI5M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When working with gradient descent it may be interesting to consider only a hadful of batches at each iteration. We can do this with Fast AI in a ver simple\n",
        "manner with the *DataLoader* class.\n",
        "\n",
        "In the following implementation, each epoch considers all of the data. However, **each epoch updates the parameters multiple times** by considering all of the data in batch form in random order. \n",
        "\n",
        "**Note on theory:** I am not completely sure this is the traditional way of doing SGD, but it was the intuition I obtained from reading the AI book\n",
        "\n",
        "**Note on speed:** Previous implementation is much faster. I suppose due to the absence of the multiple for loops that are here"
      ],
      "metadata": {
        "id": "EHcA3aP6_gq5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dset = list(zip(train_x, train_y))\n",
        "valid_dset = list(zip(valid_x, valid_y))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "8KUmlZ9tnwXD",
        "gather": {
          "logged": 1651160069305
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dl = DataLoader(train_dset, batch_size=256, shuffle=True)\n",
        "xb, yb = first(train_dl)\n",
        "print(xb.shape, yb.shape)\n",
        "\n",
        "valid_dl = DataLoader(valid_dset, batch_size=256, shuffle=True)\n",
        "xb, yb = first(valid_dl)\n",
        "print(xb.shape, yb.shape)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "mv3GAJ6VrTyi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cab61f5d-0682-40a4-dfd4-647b0fac8d52",
        "gather": {
          "logged": 1651160069321
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearModel:\n",
        "\n",
        "  def __init__(self, intercept, weights):\n",
        "    self.intercept = intercept\n",
        "    self.weights = weights\n",
        "    self.params = (intercept, weights)\n",
        "\n",
        "  def predict(self, data):\n",
        "    return data@self.weights + self.intercept\n",
        "\n",
        "\n",
        "def mnist_loss(predictions, targets): \n",
        "  predictions = predictions.sigmoid()\n",
        "  return torch.where(targets==1, 1-predictions, predictions).mean()\n",
        "\n",
        "def calc_grad(xb, yb, model, prt=True):\n",
        "  pred = model.predict(xb)\n",
        "  loss = mnist_loss(pred, yb)\n",
        "  loss.backward()\n",
        "  if prt: print(\"Loss: \" + str(loss))\n",
        "\n",
        "def train_epoch(train_dl, model, lr, prt=True):\n",
        "  for xb, yb in train_dl: # Iterates over batches, not individual instances\n",
        "    calc_grad(xb, yb, model, prt)\n",
        "    for p in model.params:\n",
        "      p.data -= p.grad * lr\n",
        "      p.grad.zero_() # See page 172, last paragraph\n",
        "  \n",
        "def hard_predict_mnist(xb, model):\n",
        "  linear_predictions = model.predict(xb)\n",
        "  predictions = linear_predictions.sigmoid()\n",
        "  return torch.where(predictions > 0.5, 1, 0)\n",
        "\n",
        "def validate_epoch(valid_dl, model):\n",
        "  batch_accs = [(hard_predict_mnist(valid_xb, model) == valid_yb).count_nonzero() \n",
        "                / valid_yb.shape[0] for valid_xb, valid_yb in valid_dl]\n",
        "  return torch.FloatTensor(batch_accs).mean()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "YzuzDkHdtYHj",
        "gather": {
          "logged": 1651160069339
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Small example just to see what was happening under the hood\n",
        "# xb and yb are now batches, not individual data instances\n",
        "\n",
        "# l = []\n",
        "# for xb, yb in train_dl:\n",
        "#   l.append(xb)\n",
        "# len(l)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "5Us5COdWvl5c",
        "gather": {
          "logged": 1651160069357
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights = init_params((28*28,1))\n",
        "intercept = init_params(1)\n",
        "linear_model = LinearModel(intercept, weights)\n",
        "n_epochs=5 \n",
        "\n",
        "for i in range(1, n_epochs):\n",
        "  train_epoch(train_dl, linear_model, 1e-3, False)\n",
        "  validation_acc = validate_epoch(valid_dl, linear_model)\n",
        "  print(\"Epoch validation accuracy: \" + str(validation_acc))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "wTWUzhmb5r4r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbc06308-1773-436c-dd8a-148ce2185b26",
        "gather": {
          "logged": 1651160069372
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Creating an optimizer**"
      ],
      "metadata": {
        "id": "XkiaUvAk96Xy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because stochastic gradient descent is such a general foundation, PyTorch provides some useful classes to make it easier to implement."
      ],
      "metadata": {
        "id": "5jCF9qK0Dt9h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicOptim:\n",
        "\n",
        "  def __init__(self, params, lr):\n",
        "    self.params = params\n",
        "    self.lr = lr\n",
        "\n",
        "  def step(self, *args, **kwargs):\n",
        "    for p in self.params:\n",
        "      p.data -= p.grad.data * self.lr\n",
        "  \n",
        "  def zero_grad(self, *args, **kwargs):\n",
        "    for p in self.params:\n",
        "      p.grad = None\n",
        "\n",
        "\n",
        "def mnist_loss(predictions, targets): \n",
        "  predictions = predictions.sigmoid()\n",
        "  return torch.where(targets==1, 1-predictions, predictions).mean()\n",
        "\n",
        "def calc_grad(xb, yb, model, prt=False):\n",
        "  pred = model(xb) # Linear does not have predict\n",
        "  loss = mnist_loss(pred, yb)\n",
        "  loss.backward()\n",
        "  if prt: print(\"Loss: \" + str(loss))\n",
        "\n",
        "def train_epoch(train_dl, model, optimizer):\n",
        "  for xb, yb in train_dl:\n",
        "    calc_grad(xb, yb, model)\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "def hard_predict_mnist(xb, model):\n",
        "  linear_predictions = model(xb) # Linear does not have predict\n",
        "  predictions = linear_predictions.sigmoid()\n",
        "  return torch.where(predictions > 0.5, 1, 0)\n",
        "\n",
        "def validate_epoch(valid_dl, model):\n",
        "  batch_accs = [(hard_predict_mnist(valid_xb, model) == valid_yb).count_nonzero() \n",
        "                / valid_yb.shape[0] for valid_xb, valid_yb in valid_dl]\n",
        "  return torch.FloatTensor(batch_accs).mean()\n",
        "\n",
        "def train_model(train_dl, valid_dl, model, optimizer, epochs):\n",
        "  for i in range(epochs):\n",
        "    train_epoch(train_dl, model, optimizer)\n",
        "    print(validate_epoch(valid_dl, model), end=\"\\n\")\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "t1y9ptsdtFJz",
        "gather": {
          "logged": 1651160069393
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "linear_model = nn.Linear(28*28, 1) # This creates a single LINEAR activation function with 28*28 input features and a single output feature\n",
        "lr=1e-3\n",
        "optimizer = BasicOptim(linear_model.parameters(), lr)\n",
        "train_model(train_dl, valid_dl, linear_model, optimizer, 5)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "XV_POSrL2QJh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10c618de-2a81-436a-e2b9-4af6a5aa6389",
        "gather": {
          "logged": 1651160069418
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Using SGD optimizer**"
      ],
      "metadata": {
        "id": "u2NZbqGi4r0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "linear_model = nn.Linear(28*28, 1)\n",
        "optimizer = SGD(linear_model.parameters(), lr)\n",
        "train_model(train_dl, valid_dl, linear_model, optimizer, 5)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "iHlLDkFZ4wkh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de319291-1047-4886-f4df-280d2c451451",
        "gather": {
          "logged": 1651160069435
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Using FastAI**"
      ],
      "metadata": {
        "id": "YjjyI9Fz3aZB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "FastAI provides a *Learner* with a *fit()* function, which we can use instead of our implementation of *train_model()*. To create a *Learner*, we first need to create *DataLoaders*, by passing in our training and validation *DataLoaders*"
      ],
      "metadata": {
        "id": "a4KT53wK3qyQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_accuracy(xb, yb):\n",
        "    preds = xb.sigmoid()\n",
        "    correct = (preds>0.5) == yb\n",
        "    return correct.float().mean()\n",
        "\n",
        "lr=1e-3\n",
        "dls = DataLoaders(train_dl, valid_dl)\n",
        "learn = Learner(dls, nn.Linear(28*28,1), opt_func=SGD,\n",
        "                loss_func=mnist_loss, metrics=batch_accuracy)\n",
        "learn.fit(5, lr)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "heuZC9lh3o5R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "459035a1-71e2-4d2e-da32-6e7cb1957e83",
        "gather": {
          "logged": 1651160069453
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Adding a Nonlinearity**\n",
        "\n",
        "We consider a different model. In this case we are going to consider a small network with 2 layers. The first layer is a linear fuction with 28*28 input features whose activaction function is a ReLU, and the second (and output) layer is a linear function with 30 input features and a single input feature"
      ],
      "metadata": {
        "id": "JBDTVUqTBRHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "simple_net = nn.Sequential(\n",
        "    nn.Linear(28*28,30),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(30,1)\n",
        "    )\n",
        "\n",
        "optimizer = SGD(simple_net.parameters(), lr)\n",
        "train_model(train_dl, valid_dl, simple_net, optimizer, 5)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "dLqPxpVpBv7P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b42890a-d885-4e35-8b1b-a5b854a69ada",
        "gather": {
          "logged": 1651160069473
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using FastAI Learner:"
      ],
      "metadata": {
        "id": "AIHNw1y4EQXH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learn = Learner(dls, simple_net, opt_func=SGD, loss_func=mnist_loss, metrics=batch_accuracy)\n",
        "learn.fit(5, lr)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "DmSyu8zeEUiX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "f1b80c5b-de73-4bd0-89a4-631133ca938e",
        "gather": {
          "logged": 1651160069490
        }
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNyEjd2meq3JnUQOONyocPo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}