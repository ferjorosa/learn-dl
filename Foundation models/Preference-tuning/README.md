Ideas:

Crear aplicacion con Arguilla para que los PMs y expertos en el dominio puedan anotar preferencias y 
generar datasets que pudieramos usar para nuestro juez o directamente para finetunear nuestros modelos.

Quizas esta idea podria tambien ayudar para nuestros parsers

https://argilla.io/blog/

Combinar DPO con PEFT:

* https://huggingface.co/blog/dpo_vlm
* https://www.cerebras.net/blog/fine-tuning-language-models-using-direct-preference-optimization