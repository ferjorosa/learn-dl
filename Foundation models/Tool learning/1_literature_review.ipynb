{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Literature review on tool learning\n",
    "\n",
    "This overview provides a condensed summary of the current advancements in tool learning using foundation models like GPT. The information presented is primarily derived from [Qin et al. (2023)](https://arxiv.org/pdf/2304.08354.pdf)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Introduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In recent years, foundation models have shown enormous semantic understanding capacity in diverse tasks, spanning the fields of natural language processing (NLP) ([Brown et al., 2020](https://arxiv.org/pdf/2005.14165.pdf)), computer vision (CV) ([Dosovitskiy et al., 2020](https://arxiv.org/pdf/2005.14165.pdf)), biology ([Jumper et al., 2021](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8371605/)), etc. Additionally, they have demonstrated superior reasoning and decision-making abilities in complex interactive environments ([Nakano et al., 2021](https://arxiv.org/pdf/2112.09332.pdf)). By harnessing the extensive world knowledge garnered during pre-training, models such as PaLM ([Chowdhery et al., 2022](https://arxiv.org/pdf/2204.02311.pdf)), GPT-4 ([OpenAI, 2023](https://arxiv.org/pdf/2303.08774.pdf)), and LLaMA ([Touvron et al., 2023](https://arxiv.org/pdf/2302.13971.pdf)) have shown the potential of foundation models to understand human intentions, automate intricate processes, and interact with the real world. However, despite their unprecedented capabilities, these state-of-the-art models still possess limitations that hinder their full potential ([Karpas et al., 2022](https://arxiv.org/pdf/2205.00445.pdf)):\n",
    "\n",
    "* **Lack of access to current information.** Certain data constantly change. For instance, the exchange rate between the dollar and the Moroccan Dirham, current COVID numbers, the stock price of AAPL, the weather in Vancouver or even the current date. It is impossible, by their design, for pretrained foundation models to keep up with this dynamic information\n",
    "\n",
    "* **Lack of access to proprietary information sources.** As an important special case of 1, the models don’t have access to proprietary information, such as the client roster in a company’s database or the state of an online game.\n",
    "\n",
    "* **Lack of probabilistic reasoning**. Probabilistic reasoning is beyond the reach of the neural approach (or it would require even more massive models that we cannot easily train/work with) and requires a dedicated reasoning process.\n",
    "\n",
    "* **Lack of mathematical skills to perform precise calculations**. Current model show great results, but it still lack precision, especially when dealing with float numbers.\n",
    "\n",
    "<span style=\"color:red\"><b>TODO: Tabla con diferentes imagenes de ejemplos, una para cada punto</b></span>\n",
    "\n",
    "An effective and cost-efficient solution to address the limitations of current foundation models is to equip them with the ability to utilize external tools such as search engines, calculators, calendars, etc. By combining the understanding and reasoning capabilities of foundation models with specialized tools, we can create intelligent agents that are capable of tackling more complex tasks than what either specialized tools or foundation models can achieve individually. This fusion of capabilities offers numerous benefits ([Qin et al. (2023)](https://arxiv.org/pdf/2304.08354.pdf)), including:\n",
    "\n",
    "* **Mitigation for memorization**. Foundation models, despite their impressive memorization abilities ([Carlini et al., 2021](https://arxiv.org/pdf/2012.07805.pdf), [2022](https://arxiv.org/pdf/2202.07646.pdf), [2023](https://arxiv.org/pdf/2301.13188.pdf)), cannot memorize all training data or effectively steer the memorized knowledge. By integrating tools, foundation models can offload the memorization burden to external resources like search engines, ensuring real-time access to up-to-date knowledge and reducing the risk of generating non-factual content ([Shuster et al., 2021](https://arxiv.org/pdf/2104.07567.pdf)).\n",
    "\n",
    "* **Enhanced expertise**. Specialized tools offer functionalities that are not available in foundation models. They are designed to cater to specific domains and can address the needs of domain-specific tasks more effectively. By incorporating specialized tools, foundation models can leverage their capabilities to generalize and handle a wider range of tasks beyond their own limitations.\n",
    "\n",
    "* **Better interpretability**. Foundation models are often criticized for lacking transparency in their decision-making process ([Linardatos et al., 2020](https://www.mdpi.com/1099-4300/23/1/18)). This can be a concern in critical domains like healthcare or finance where explainability is crucial. In contrast, the process of tool execution provides better interpretability and transparency. Users can understand why specific tools are used and how they contribute to the final output, fostering trust and enabling effective collaboration between humans and machines.\n",
    "  \n",
    "* **Improved robustness**. Foundation models are vulnerable to adversarial attacks, where slight input modifications can manipulate their predictions ([Jin et al., 2020](https://arxiv.org/pdf/1907.11932.pdf); [Liu et al., 2023](https://arxiv.org/pdf/2305.13860.pdf)). This susceptibility arises from their reliance on statistical patterns in training data. In contrast, tools are designed for specific use cases and may be agnostic to input perturbations, making them more resilient to adversarial attacks. Incorporating tools into the workflow of foundation models enhances the system's robustness and reduces the risk of malicious attacks, ensuring greater reliability in unpredictable real-world environments.\n",
    "  \n",
    "* **Improved decision-making and reasoning abilities** Foundation models are trained on vast amounts of data, allowing them to acquire extensive world knowledge. This knowledge can be utilized for decision-making and long-term planning ([Huang et al., 2022](https://arxiv.org/pdf/2201.07207.pdf)), as well as for extrapolating consequences and making informed judgments ([Wei et al., 2023](https://arxiv.org/pdf/2201.11903.pdf); [Wang et al., 2023](https://arxiv.org/pdf/2203.11171.pdf)). In this context, tools can improve consistency and increase reasoning capacity.\n",
    "  \n",
    "* **Better user experience**. Benefitting from the powerful intent understanding capability of foundation models, tool learning could revolutionize the way we interact with machines and liberate users from the cognition load, allowing them to engage in higher-order thinking and decision-making processes.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Literature review on tool learning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the perspective of learning objectives, tool learning can be categorized into two main groups: **tool-augmented learning** and **tool-oriented learning**.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"./images_1/types_tool_learning.PNG\" width=\"800\" data-align=\"center\"/></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Image from <a href=\"https://arxiv.org/pdf/2304.08354.pdf\">Qin et al. (2023)</a></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 - Tool-augmented learning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tool-augmented learning seeks to augment foundation models with the execution results from tools**. In this paradigm, tools are viewed as complementary resources that can enable models to effectively incorporate domain-specific knowledge and improve their generation quality. Research in this area has primarily focused on augmenting models with external knowledge sources, such as unstructured raw text and domain-specific APIs."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 - Retrieval-augmented learning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieval-augmented learning is a technique that uses text retriever tools to enhance language generation. These tools have evolved from early sparse retrievers to more recent dense retrievers. \n",
    "\n",
    "Early endeavors resort to retrieving knowledge from local repositories to augment language generation. Some works propose retrieving knowledge using a frozen knowledge retriever ([Khandelwal et al., 2020](https://openreview.net/forum?id=HklBjCEKvH); [Borgeaud et al., 2022](https://proceedings.mlr.press/v162/borgeaud22a.html)). Another line of work trains the retriever and the language model an end-to-end fashion, achieving superior performance in knowledge-intensive NLP tasks ([Lewis et al., 2020](https://proceedings.neurips.cc/paper/2020/hash/6b493230205f780e1bc26945df7481e5-Abstract.html); [Izacard et al., 2022](https://arxiv.org/pdf/2208.03299.pdf))\n",
    "\n",
    "Recent advancements in retrieval-augmented learning have expanded beyond local repositories to leverage the entire web as a knowledge source. This enables improved temporal generalization and factual accuracy ([Menick et al., 2022](https://arxiv.org/pdf/2203.11147.pdf); [Lazaridou et al., 2022](https://arxiv.org/pdf/2203.05115.pdf)). Researchers have also shown that language models can actively interact with search engines, similar to how humans do. For instance, dialogue agents like Blender-Bot ([Shuster et al, 2022](https://arxiv.org/pdf/2208.03188.pdf)) and LaMDA ([Thoppilan et al., 2022](https://arxiv.org/pdf/2201.08239.pdf)) actively decide when and how to call a search engine to generate responses.\n",
    "\n",
    "Retrieval-augmented learning has also been explored in vision foundation models, allowing text-to-image models to generate more realistic and faithful images by accessing external multi-modal knowledge sources ([Blattmann et al., 2022](https://arxiv.org/pdf/2204.11824.pdf); [Sheynin et al., 2022](https://arxiv.org/pdf/2204.02849.pdf)).\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 - Augmentation with other tools"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Researchers have explored the use of various tools to perform specific sub-tasks and integrate the results into foundation models. [Cobbe et al. (2021)](https://arxiv.org/pdf/2110.14168.pdf) trained a language model to use a calculator for basic arithmetic operations. [Parisi et al. (2022)](https://arxiv.org/pdf/2205.12255.pdf) investigated the interleaving of text-based API calls, such as a question-answering system and a calculator, with language generation. They demonstrated that iteratively bootstrapping tool-use examples improved the model's ability to utilize the tool effectively.\n",
    "\n",
    "Toolformer ([Schick et al., 2023](https://arxiv.org/pdf/2302.04761.pdf)) extended this idea to a broader setting and explored the usage of multiple simple tools, including a QA system, calculator, machine translation system, Wikipedia searching tool, and calendar. They provided an exemplary generation of Toolformer and showed that foundation models can learn to utilize a tool with a few demonstrations in a self-supervised manner.\n",
    "\n",
    "[Liu et al. (2022)](https://arxiv.org/pdf/2210.05359.pdf) addressed the limitation of language models in understanding and interacting with the physical world by incorporating a physics simulation engine (MuJoCo) to ground their reasoning in the real world. This augmentation significantly enhanced the language model's physical understanding and reasoning abilities.\n",
    "\n",
    "[Chen et al. (2022)](https://arxiv.org/pdf/2211.12588.pdf) and [Gao et al. (2022)](https://arxiv.org/pdf/2211.10435.pdf) proposed augmenting language models with Python interpreters, where language models generate programs for complex tasks and the execution is offloaded to Python interpreters, leading to superior performance in mathematical and symbolic reasoning tasks.\n",
    "\n",
    "[Nye et al. (2021)](https://arxiv.org/pdf/2112.00114.pdf) augmented language models with a scratchpad, allowing them to emit intermediate task-solving procedures, leading to enhanced performance in complex discrete computations. \n",
    "\n",
    "[Wang et al. (2022)](https://arxiv.org/pdf/2210.07382.pdf) demonstrated that incorporating symbolic modules, such as arithmetic and navigation, into the action space improved agent performance in interactive fiction games. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 - Tool-oriented learning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tool-oriented learning aims to improve decision-making and interaction in complex tasks by making sequential decisions and utilizing tools**. However, existing methods in this domain often rely on domain-specific data, leading to limited generalization capabilities and training efficiency. Researchers have recognized the significance of prior knowledge for transferability and have explored **leveraging foundation models' vast world knowledge and reasoning ability**. By integrating these models, it becomes possible to enhance decision-making and interaction in complex environments ([Yang et al., 2023a](https://arxiv.org/pdf/2303.04129.pdf); [Li et al., 2023](https://arxiv.org/pdf/2302.02801.pdf))."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 - Embodied robotic learning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most representative application of tool-oriented learning is robotic\n",
    "manipulation, where large-scale language models are treated as the “brain” of the system. Researchers have explored the planning ability of these models, showcasing their capability to decompose high-level tasks and generate plausible sub-plans ([Huang et al., 2022a](https://proceedings.mlr.press/v162/huang22a.html)). However, since language models are not grounded in the environment, they may generate unrealistic and nonsensical plans. To address this issue, methods like SayCan focus on actions that the agent is \"permitted\" to execute, enhancing the agent's physical grounding in the environment ([Ahn et al., 2022](https://arxiv.org/pdf/2204.01691.pdf)). Feedback from the environment is also considered in decision-making, as seen in the integration of textual feedback and scene information to generate more feasible plans ([Huang et al., 2022b](https://arxiv.org/pdf/2207.05608.pdf)). To further streamline the planning process, [Liang et al (2022)](https://arxiv.org/pdf/2209.07753.pdf)  utilizes language models to directly generate executable robot policy codes, eliminating the need for pre-defining how to map the sub-plans to executable actions. \n",
    "\n",
    "While previous works are generally confined to limited robotic tasks, [Vemprala et al. (2023)](https://www.microsoft.com/en-us/research/publication/chatgpt-for-robotics-design-principles-and-model-abilities/) recently show ChatGPT is a versatile robotic controller. Through sophisticated prompt engineering, ChatGPT is capable of understanding user instructions and executing a variety of robotic tasks unexpected before.\n",
    "\n",
    "As the centerpiece for planning and reasonin, language models are highly effective in processing textual inputs, but they have limitations when it comes to tools that produce outputs in different modalities. To address this, various approaches have been explored to unify the outputs of different modality tools. One common approach involves combining a frozen language model with tools in the textual space, where the outputs of foundation models from different modalities are converted into natural languages ([Zeng et al., 2022](https://arxiv.org/pdf/2204.00598.pdf)). This method leverages prompting to create new multimodal capabilities without the need for fine-tuning.\n",
    "\n",
    "Another direction of research involves building multimodal foundation models capable of perceiving general modalities. The idea is that these multimodal models can be unified through a general-purpose interface ([Hao et al., 2022](https://arxiv.org/pdf/2206.06336.pdf)). A well-known example of this idea is Flamingo ([Alayrac et al., 2022](https://arxiv.org/pdf/2204.14198.pdf)). Other example is Gato, a representative generalist multi-embodiment agent trained on extensive datasets of agent experience ([Reed et al., 2022](https://arxiv.org/pdf/2205.06175.pdf)). Gato can perceive and interact with different embodiments, such as playing Atari, captioning images, and engaging in conversations.\n",
    "\n",
    "Similarly, PaLM-E incorporates continuous inputs from various modalities into a language model ([Driess et al., 2023](https://arxiv.org/pdf/2303.03378.pdf)). By jointly training on multiple embodied tasks, PaLM-E enables grounded decision-making in real-world scenarios.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 - Other purposes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tool-oriented learning, beyond robotic applications, has found use in various scenarios. These include:\n",
    "\n",
    "* **Web search automation**. WebGPT ([Nakano et al., 2021](https://arxiv.org/pdf/2112.09332.pdf)) interacts with search engines by refining search queries and capturing important information. Through fine-tuning GPT-3 to emulate human web search behaviors, the model demonstrates exceptional capabilities in manipulating search engines for information retrieval, surpassing human experts.\n",
    "\n",
    "* **Online shopping**. WebShop ([Yao et al., 2022](https://arxiv.org/pdf/2207.01206.pdf)) provides an interactive web-based environment where an agent can browse and purchase products. Trained through behavior cloning, the agent exhibits significant performance in accurately selecting the right products based on human instructions.\n",
    "\n",
    "* **Dialogue-based image drawing and editing**. Visual ChatGPT ([Wu et al., 2023](https://arxiv.org/pdf/2303.04671.pdf)) combines ChatGPT with vision foundation models to enable image understanding and generation. ChatGPT serves as the core controller, making sequential decisions and potentially utilizing vision models to modify images or respond with text.\n",
    "\n",
    "* **Integration of existing neural models**. HuggingGPT ([Shen et al., 2023](https://arxiv.org/pdf/2303.17580.pdf)) proposes connecting existing models hosted by Huggingface using a universal language interface (ChatGPT). Acting as the \"brain\" for task planning, ChatGPT calls upon specialized models for tasks in specific domains, such as object detection and question answering.\n",
    "\n",
    "* **Computer manipulation**. [Kim et al. (2023)](https://arxiv.org/pdf/2303.17491.pdf) suggest prompting large language models to execute computer tasks. By considering task and state information, these models generate grounded actions and achieve impressive performance on tasks like MiniWoB++.\n",
    "\n",
    "In addition, [Auto-GPT](https://github.com/Significant-Gravitas/Auto-GPT) demonstrates the potential of foundation models in automating various tools and making long-term plans. Given a user query, Auto-GPT autonomously performs step-by-step actions to accomplish objectives. Additionally, it can reflect on past actions to refine decision-making."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
