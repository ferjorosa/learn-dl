{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ferjorosa/learn-fastai/blob/main/12%20-%20A%20Language%20Model%20from%20Scratch/12_chapter_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZFkk3hdyxSWD",
        "outputId": "f020573a-4cc8-4353-bc0a-cb9d1a720e72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 189 kB 24.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.9 MB/s \n",
            "\u001b[?25h2.5.3\n",
            "\u001b[K     |████████████████████████████████| 720 kB 16.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 5.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 48 kB 3.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 558 kB 40.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 51 kB 226 kB/s \n",
            "\u001b[K     |████████████████████████████████| 130 kB 44.7 MB/s \n",
            "\u001b[?25hMounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "#hide (Google Colab)\n",
        "!pip install fastai --upgrade -q\n",
        "import fastai\n",
        "print(fastai.__version__)\n",
        "\n",
        "!pip install -Uqq fastbook\n",
        "import fastbook\n",
        "fastbook.setup_book()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QsIdo0CDxSWF"
      },
      "outputs": [],
      "source": [
        "#hide\n",
        "from fastbook import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaws9qzxxSWH"
      },
      "source": [
        "# A Language Model from Scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u38vPisuxSWJ"
      },
      "source": [
        "## The Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "K-QDJzdaxSWK",
        "outputId": "82a32e26-b5a4-428e-e027-fc7edaa1ca96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='32768' class='' max='30252' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      108.32% [32768/30252 00:00<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from fastai.text.all import *\n",
        "path = untar_data(URLs.HUMAN_NUMBERS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Pt2P6VbIxSWM"
      },
      "outputs": [],
      "source": [
        "#hide\n",
        "Path.BASE_PATH = path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3hSzqI0lxSWN",
        "outputId": "421b7427-2783-4ab1-9e66-2dc34afc4211",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#2) [Path('valid.txt'),Path('train.txt')]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "path.ls()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "n6ooKSmmxSWO",
        "outputId": "cfef310f-f214-4b58-8e54-46a0dff892c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#9998) ['one \\n','two \\n','three \\n','four \\n','five \\n','six \\n','seven \\n','eight \\n','nine \\n','ten \\n'...]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "lines = L()\n",
        "with open(path/'train.txt') as f: lines += L(*f.readlines())\n",
        "with open(path/'valid.txt') as f: lines += L(*f.readlines())\n",
        "lines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "0PanFyF_xSWO",
        "outputId": "57992168-f764-422b-cd5d-eddd9e344873",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'one . two . three . four . five . six . seven . eight . nine . ten . eleven . twelve . thirteen . fo'"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "text = ' . '.join([l.strip() for l in lines])\n",
        "text[:100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "wiSLVlgBxSWP",
        "outputId": "316dd3af-06fc-4df1-84f7-5863da991312",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['one', '.', 'two', '.', 'three', '.', 'four', '.', 'five', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "tokens = text.split(' ')\n",
        "tokens[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "DeaylaYfxSWQ",
        "outputId": "7b3ce95c-6175-4ee5-dcaa-fb5ea6da6e1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#30) ['one','.','two','three','four','five','six','seven','eight','nine'...]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "vocab = L(*tokens).unique()\n",
        "vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "FVu7i8K1xSWS",
        "outputId": "644b6fda-6872-4d35-b728-f48c2ab152eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#63095) [0,1,2,1,3,1,4,1,5,1...]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "word2idx = {w:i for i,w in enumerate(vocab)}\n",
        "nums = L(word2idx[i] for i in tokens)\n",
        "nums"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kc_8v1b8xSWS"
      },
      "source": [
        "## Our First Language Model from Scratch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "tAEEKSmkxSWT",
        "outputId": "9145ee57-2680-4031-8766-2079ab8078a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#21031) [(['one', '.', 'two'], '.'),(['.', 'three', '.'], 'four'),(['four', '.', 'five'], '.'),(['.', 'six', '.'], 'seven'),(['seven', '.', 'eight'], '.'),(['.', 'nine', '.'], 'ten'),(['ten', '.', 'eleven'], '.'),(['.', 'twelve', '.'], 'thirteen'),(['thirteen', '.', 'fourteen'], '.'),(['.', 'fifteen', '.'], 'sixteen')...]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "L((tokens[i:i+3], tokens[i+3]) for i in range(0,len(tokens)-4,3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "mZa4HL7mxSWT",
        "outputId": "e1351ccc-ba3e-4bba-aef3-d6af186c5937",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#21031) [(tensor([0, 1, 2]), 1),(tensor([1, 3, 1]), 4),(tensor([4, 1, 5]), 1),(tensor([1, 6, 1]), 7),(tensor([7, 1, 8]), 1),(tensor([1, 9, 1]), 10),(tensor([10,  1, 11]), 1),(tensor([ 1, 12,  1]), 13),(tensor([13,  1, 14]), 1),(tensor([ 1, 15,  1]), 16)...]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "seqs = L((tensor(nums[i:i+3]), nums[i+3]) for i in range(0,len(nums)-4,3))\n",
        "seqs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "omvxISvGxSWU"
      },
      "outputs": [],
      "source": [
        "bs = 64\n",
        "cut = int(len(seqs) * 0.8)\n",
        "dls = DataLoaders.from_dsets(seqs[:cut], seqs[cut:], bs=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybIniUyvxSWU"
      },
      "source": [
        "### Our Language Model in PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "XFzxrcg-xSWV"
      },
      "outputs": [],
      "source": [
        "class LMModel1(Module):\n",
        "    def __init__(self, vocab_sz, n_hidden):\n",
        "        self.i_h = nn.Embedding(vocab_sz, n_hidden)  \n",
        "        self.h_h = nn.Linear(n_hidden, n_hidden)     \n",
        "        self.h_o = nn.Linear(n_hidden,vocab_sz)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        h = F.relu(self.h_h(self.i_h(x[:,0])))\n",
        "        h = h + self.i_h(x[:,1])\n",
        "        h = F.relu(self.h_h(h))\n",
        "        h = h + self.i_h(x[:,2])\n",
        "        h = F.relu(self.h_h(h))\n",
        "        return self.h_o(h)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "zGoS1pCHxSWW",
        "outputId": "2faf5f16-28d2-4e2b-a803-ed14ef58b936",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.824297</td>\n",
              "      <td>1.970941</td>\n",
              "      <td>0.467554</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.386973</td>\n",
              "      <td>1.823242</td>\n",
              "      <td>0.467554</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.417556</td>\n",
              "      <td>1.654498</td>\n",
              "      <td>0.494414</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.376440</td>\n",
              "      <td>1.650849</td>\n",
              "      <td>0.494414</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "learn = Learner(dls, LMModel1(len(vocab), 64), loss_func=F.cross_entropy, \n",
        "                metrics=accuracy)\n",
        "learn.fit_one_cycle(4, 1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "WwiSvJYbxSWW",
        "outputId": "988d5fcd-8082-4aad-c33f-a128925629c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(29), 'thousand', 0.15165200855716662)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "n,counts = 0,torch.zeros(len(vocab))\n",
        "for x,y in dls.valid:\n",
        "    n += y.shape[0]\n",
        "    for i in range_of(vocab): counts[i] += (y==i).long().sum()\n",
        "idx = torch.argmax(counts)\n",
        "idx, vocab[idx.item()], counts[idx].item()/n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnYH3KsRxSWW"
      },
      "source": [
        "### Our First Recurrent Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "aYmF3R0XxSWW"
      },
      "outputs": [],
      "source": [
        "class LMModel2(Module):\n",
        "    def __init__(self, vocab_sz, n_hidden):\n",
        "        self.i_h = nn.Embedding(vocab_sz, n_hidden)  \n",
        "        self.h_h = nn.Linear(n_hidden, n_hidden)     \n",
        "        self.h_o = nn.Linear(n_hidden,vocab_sz)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        h = 0\n",
        "        for i in range(3):\n",
        "            h = h + self.i_h(x[:,i])\n",
        "            h = F.relu(self.h_h(h))\n",
        "        return self.h_o(h)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "OJzFDsmhxSWX",
        "outputId": "3568f6a2-9b5e-4d7e-b758-6267aae4c98b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.816274</td>\n",
              "      <td>1.964143</td>\n",
              "      <td>0.460185</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.423805</td>\n",
              "      <td>1.739964</td>\n",
              "      <td>0.473259</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.430327</td>\n",
              "      <td>1.685172</td>\n",
              "      <td>0.485382</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.388390</td>\n",
              "      <td>1.657033</td>\n",
              "      <td>0.470406</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "learn = Learner(dls, LMModel2(len(vocab), 64), loss_func=F.cross_entropy, \n",
        "                metrics=accuracy)\n",
        "learn.fit_one_cycle(4, 1e-3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83EmkawZxSWX"
      },
      "source": [
        "## Improving the RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzIJh11ZxSWY"
      },
      "source": [
        "### Maintaining the State of an RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "UU0GyS3WxSWY"
      },
      "outputs": [],
      "source": [
        "class LMModel3(Module):\n",
        "    def __init__(self, vocab_sz, n_hidden):\n",
        "        self.i_h = nn.Embedding(vocab_sz, n_hidden)  \n",
        "        self.h_h = nn.Linear(n_hidden, n_hidden)     \n",
        "        self.h_o = nn.Linear(n_hidden,vocab_sz)\n",
        "        self.h = 0\n",
        "        \n",
        "    def forward(self, x):\n",
        "        for i in range(3):\n",
        "            self.h = self.h + self.i_h(x[:,i])\n",
        "            self.h = F.relu(self.h_h(self.h))\n",
        "        out = self.h_o(self.h)\n",
        "        self.h = self.h.detach()\n",
        "        return out\n",
        "    \n",
        "    def reset(self): self.h = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "wxOgoRZvxSWY",
        "outputId": "3087754a-f6e1-4536-f098-5542a0b70180",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(328, 64, 21031)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "m = len(seqs)//bs\n",
        "m,bs,len(seqs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "yRnA0qgoxSWZ"
      },
      "outputs": [],
      "source": [
        "def group_chunks(ds, bs):\n",
        "    m = len(ds) // bs\n",
        "    new_ds = L()\n",
        "    for i in range(m): new_ds += L(ds[i + m*j] for j in range(bs))\n",
        "    return new_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "6cPsXaGAxSWZ"
      },
      "outputs": [],
      "source": [
        "cut = int(len(seqs) * 0.8)\n",
        "dls = DataLoaders.from_dsets(\n",
        "    group_chunks(seqs[:cut], bs), \n",
        "    group_chunks(seqs[cut:], bs), \n",
        "    bs=bs, drop_last=True, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "jc7T7w37xSWZ",
        "outputId": "f53b120e-42ff-46cb-f2f5-8ddeb4206058",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.677074</td>\n",
              "      <td>1.827367</td>\n",
              "      <td>0.467548</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.282721</td>\n",
              "      <td>1.870913</td>\n",
              "      <td>0.388942</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.090705</td>\n",
              "      <td>1.651793</td>\n",
              "      <td>0.462500</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.005216</td>\n",
              "      <td>1.615990</td>\n",
              "      <td>0.515144</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.963020</td>\n",
              "      <td>1.605894</td>\n",
              "      <td>0.551202</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.925863</td>\n",
              "      <td>1.717049</td>\n",
              "      <td>0.543750</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.902744</td>\n",
              "      <td>1.704875</td>\n",
              "      <td>0.550721</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.844484</td>\n",
              "      <td>1.831642</td>\n",
              "      <td>0.566106</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.806782</td>\n",
              "      <td>1.837001</td>\n",
              "      <td>0.582452</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.795707</td>\n",
              "      <td>1.842007</td>\n",
              "      <td>0.573798</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "learn = Learner(dls, LMModel3(len(vocab), 64), loss_func=F.cross_entropy,\n",
        "                metrics=accuracy, cbs=ModelResetter)\n",
        "learn.fit_one_cycle(10, 3e-3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWZ0nMdPxSWZ"
      },
      "source": [
        "### Creating More Signal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "wn51OGWtxSWa"
      },
      "outputs": [],
      "source": [
        "sl = 16\n",
        "seqs = L((tensor(nums[i:i+sl]), tensor(nums[i+1:i+sl+1]))\n",
        "         for i in range(0,len(nums)-sl-1,sl))\n",
        "cut = int(len(seqs) * 0.8)\n",
        "dls = DataLoaders.from_dsets(group_chunks(seqs[:cut], bs),\n",
        "                             group_chunks(seqs[cut:], bs),\n",
        "                             bs=bs, drop_last=True, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "A6ae19DTxSWa",
        "outputId": "d13bc605-44bc-4d10-9c70-8e294969ab17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(#16) ['one','.','two','.','three','.','four','.','five','.'...],\n",
              " (#16) ['.','two','.','three','.','four','.','five','.','six'...]]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "[L(vocab[o] for o in s) for s in seqs[0]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "ieNNUMyjxSWa"
      },
      "outputs": [],
      "source": [
        "class LMModel4(Module):\n",
        "    def __init__(self, vocab_sz, n_hidden):\n",
        "        self.i_h = nn.Embedding(vocab_sz, n_hidden)  \n",
        "        self.h_h = nn.Linear(n_hidden, n_hidden)     \n",
        "        self.h_o = nn.Linear(n_hidden,vocab_sz)\n",
        "        self.h = 0\n",
        "        \n",
        "    def forward(self, x):\n",
        "        outs = []\n",
        "        for i in range(sl):\n",
        "            self.h = self.h + self.i_h(x[:,i])\n",
        "            self.h = F.relu(self.h_h(self.h))\n",
        "            outs.append(self.h_o(self.h))\n",
        "        self.h = self.h.detach()\n",
        "        return torch.stack(outs, dim=1)\n",
        "    \n",
        "    def reset(self): self.h = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "nE1OlLsOxSWb"
      },
      "outputs": [],
      "source": [
        "def loss_func(inp, targ):\n",
        "    return F.cross_entropy(inp.view(-1, len(vocab)), targ.view(-1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "ZC4_1HT6xSWb",
        "outputId": "fe6714b8-c716-4e15-c4f3-fd6f124913d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.285931</td>\n",
              "      <td>3.072032</td>\n",
              "      <td>0.212565</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.330371</td>\n",
              "      <td>1.969522</td>\n",
              "      <td>0.425781</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.742317</td>\n",
              "      <td>1.841378</td>\n",
              "      <td>0.441488</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.470120</td>\n",
              "      <td>1.810857</td>\n",
              "      <td>0.494303</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.297998</td>\n",
              "      <td>1.867458</td>\n",
              "      <td>0.480062</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.175159</td>\n",
              "      <td>1.766366</td>\n",
              "      <td>0.533366</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.067657</td>\n",
              "      <td>1.775915</td>\n",
              "      <td>0.529541</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.974524</td>\n",
              "      <td>1.720501</td>\n",
              "      <td>0.545980</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.895532</td>\n",
              "      <td>1.703532</td>\n",
              "      <td>0.563802</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.828987</td>\n",
              "      <td>1.617173</td>\n",
              "      <td>0.586019</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.778963</td>\n",
              "      <td>1.712638</td>\n",
              "      <td>0.577148</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.737100</td>\n",
              "      <td>1.677089</td>\n",
              "      <td>0.612223</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.710022</td>\n",
              "      <td>1.788983</td>\n",
              "      <td>0.587646</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.693697</td>\n",
              "      <td>1.782458</td>\n",
              "      <td>0.594564</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.676122</td>\n",
              "      <td>1.772856</td>\n",
              "      <td>0.597087</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "learn = Learner(dls, LMModel4(len(vocab), 64), loss_func=loss_func,\n",
        "                metrics=accuracy, cbs=ModelResetter)\n",
        "learn.fit_one_cycle(15, 3e-3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRbVblJWxSWb"
      },
      "source": [
        "## Multilayer RNNs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UJQpXXmxSWc"
      },
      "source": [
        "### The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "R1a7CqD0xSWc"
      },
      "outputs": [],
      "source": [
        "class LMModel5(Module):\n",
        "    def __init__(self, vocab_sz, n_hidden, n_layers):\n",
        "        self.i_h = nn.Embedding(vocab_sz, n_hidden)\n",
        "        self.rnn = nn.RNN(n_hidden, n_hidden, n_layers, batch_first=True)\n",
        "        self.h_o = nn.Linear(n_hidden, vocab_sz)\n",
        "        self.h = torch.zeros(n_layers, bs, n_hidden)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        res,h = self.rnn(self.i_h(x), self.h)\n",
        "        self.h = h.detach()\n",
        "        return self.h_o(res)\n",
        "    \n",
        "    def reset(self): self.h.zero_()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "BM7doixFxSWc",
        "outputId": "1ab034a9-ed5b-46fa-99c3-5f80b40b17e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.041790</td>\n",
              "      <td>2.548715</td>\n",
              "      <td>0.455811</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.128514</td>\n",
              "      <td>1.708763</td>\n",
              "      <td>0.471029</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.699163</td>\n",
              "      <td>1.866050</td>\n",
              "      <td>0.340576</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.499681</td>\n",
              "      <td>1.738478</td>\n",
              "      <td>0.471517</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.339090</td>\n",
              "      <td>1.729539</td>\n",
              "      <td>0.494792</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.206317</td>\n",
              "      <td>1.835857</td>\n",
              "      <td>0.502848</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.088241</td>\n",
              "      <td>1.845553</td>\n",
              "      <td>0.520101</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.982788</td>\n",
              "      <td>1.856251</td>\n",
              "      <td>0.522624</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.890792</td>\n",
              "      <td>1.940332</td>\n",
              "      <td>0.525716</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.809586</td>\n",
              "      <td>2.028804</td>\n",
              "      <td>0.529785</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.743084</td>\n",
              "      <td>2.074600</td>\n",
              "      <td>0.535075</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.694127</td>\n",
              "      <td>2.153410</td>\n",
              "      <td>0.540039</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.660761</td>\n",
              "      <td>2.137607</td>\n",
              "      <td>0.547689</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.640679</td>\n",
              "      <td>2.169348</td>\n",
              "      <td>0.547363</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.630332</td>\n",
              "      <td>2.168198</td>\n",
              "      <td>0.548828</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "learn = Learner(dls, LMModel5(len(vocab), 64, 2), \n",
        "                loss_func=CrossEntropyLossFlat(), \n",
        "                metrics=accuracy, cbs=ModelResetter)\n",
        "learn.fit_one_cycle(15, 3e-3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxZj0j8RxSWd"
      },
      "source": [
        "### Exploding or Disappearing Activations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_NqZNWZxSWd"
      },
      "source": [
        "## LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANKLfSWtxSWe"
      },
      "source": [
        "### Building an LSTM from Scratch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "4E9QdOLcxSWe"
      },
      "outputs": [],
      "source": [
        "class LSTMCell(Module):\n",
        "    def __init__(self, ni, nh):\n",
        "        self.forget_gate = nn.Linear(ni + nh, nh)\n",
        "        self.input_gate  = nn.Linear(ni + nh, nh)\n",
        "        self.cell_gate   = nn.Linear(ni + nh, nh)\n",
        "        self.output_gate = nn.Linear(ni + nh, nh)\n",
        "\n",
        "    def forward(self, input, state):\n",
        "        h,c = state\n",
        "        h = torch.cat([h, input], dim=1)\n",
        "        forget = torch.sigmoid(self.forget_gate(h))\n",
        "        c = c * forget\n",
        "        inp = torch.sigmoid(self.input_gate(h))\n",
        "        cell = torch.tanh(self.cell_gate(h))\n",
        "        c = c + inp * cell\n",
        "        out = torch.sigmoid(self.output_gate(h))\n",
        "        h = out * torch.tanh(c)\n",
        "        return h, (h,c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "SsnVCBK5xSWe"
      },
      "outputs": [],
      "source": [
        "class LSTMCell(Module):\n",
        "    def __init__(self, ni, nh):\n",
        "        self.ih = nn.Linear(ni,4*nh)\n",
        "        self.hh = nn.Linear(nh,4*nh)\n",
        "\n",
        "    def forward(self, input, state):\n",
        "        h,c = state\n",
        "        # One big multiplication for all the gates is better than 4 smaller ones\n",
        "        gates = (self.ih(input) + self.hh(h)).chunk(4, 1)\n",
        "        ingate,forgetgate,outgate = map(torch.sigmoid, gates[:3])\n",
        "        cellgate = gates[3].tanh()\n",
        "\n",
        "        c = (forgetgate*c) + (ingate*cellgate)\n",
        "        h = outgate * c.tanh()\n",
        "        return h, (h,c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Wnmx0jM8xSWf",
        "outputId": "449b206c-0a63-4036-f852-416576e75fae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "t = torch.arange(0,10); t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "HHl_TZYOxSWf",
        "outputId": "548e843a-af33-4112-8296-f99c5b852460",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0, 1, 2, 3, 4]), tensor([5, 6, 7, 8, 9]))"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "t.chunk(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyYPhxR7xSWf"
      },
      "source": [
        "### Training a Language Model Using LSTMs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "aCroMWTPxSWg"
      },
      "outputs": [],
      "source": [
        "class LMModel6(Module):\n",
        "    def __init__(self, vocab_sz, n_hidden, n_layers):\n",
        "        self.i_h = nn.Embedding(vocab_sz, n_hidden)\n",
        "        self.rnn = nn.LSTM(n_hidden, n_hidden, n_layers, batch_first=True)\n",
        "        self.h_o = nn.Linear(n_hidden, vocab_sz)\n",
        "        self.h = [torch.zeros(n_layers, bs, n_hidden) for _ in range(2)]\n",
        "        \n",
        "    def forward(self, x):\n",
        "        res,h = self.rnn(self.i_h(x), self.h)\n",
        "        self.h = [h_.detach() for h_ in h]\n",
        "        return self.h_o(res)\n",
        "    \n",
        "    def reset(self): \n",
        "        for h in self.h: h.zero_()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "n5bI2hrxxSWg",
        "outputId": "3f481970-ca27-430a-e36c-07363ceb3031",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.026114</td>\n",
              "      <td>2.772102</td>\n",
              "      <td>0.153076</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.216185</td>\n",
              "      <td>2.089064</td>\n",
              "      <td>0.269124</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.613939</td>\n",
              "      <td>1.826104</td>\n",
              "      <td>0.478760</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.315262</td>\n",
              "      <td>2.047196</td>\n",
              "      <td>0.505290</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.085640</td>\n",
              "      <td>1.999898</td>\n",
              "      <td>0.595784</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.857535</td>\n",
              "      <td>2.006861</td>\n",
              "      <td>0.614339</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.601826</td>\n",
              "      <td>1.938793</td>\n",
              "      <td>0.655680</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.386586</td>\n",
              "      <td>1.886879</td>\n",
              "      <td>0.707926</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.228619</td>\n",
              "      <td>1.672689</td>\n",
              "      <td>0.748942</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.135815</td>\n",
              "      <td>1.693481</td>\n",
              "      <td>0.755941</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.081174</td>\n",
              "      <td>1.745847</td>\n",
              "      <td>0.766764</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.053281</td>\n",
              "      <td>1.654647</td>\n",
              "      <td>0.774333</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.038127</td>\n",
              "      <td>1.731585</td>\n",
              "      <td>0.770508</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.030500</td>\n",
              "      <td>1.713020</td>\n",
              "      <td>0.775146</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.027060</td>\n",
              "      <td>1.717979</td>\n",
              "      <td>0.773600</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "learn = Learner(dls, LMModel6(len(vocab), 64, 2), \n",
        "                loss_func=CrossEntropyLossFlat(), \n",
        "                metrics=accuracy, cbs=ModelResetter)\n",
        "learn.fit_one_cycle(15, 1e-2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpLIVuFoxSWh"
      },
      "source": [
        "## Regularizing an LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6QQyLBdxSWh"
      },
      "source": [
        "### Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "ktMuR7KaxSWi"
      },
      "outputs": [],
      "source": [
        "class Dropout(Module):\n",
        "    def __init__(self, p): self.p = p\n",
        "    def forward(self, x):\n",
        "        if not self.training: return x\n",
        "        mask = x.new(*x.shape).bernoulli_(1-p)\n",
        "        return x * mask.div_(1-p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgLJSkQlxSWi"
      },
      "source": [
        "### Activation Regularization and Temporal Activation Regularization"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Example TAR"
      ],
      "metadata": {
        "id": "YqLZ_4hY1ZT6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.randn(2,4,5) # bs = 2, sl = 4, n_hid = 5\n",
        "a"
      ],
      "metadata": {
        "id": "W3rtBbEM1Ydh",
        "outputId": "475e1c70-8324-4c09-87cb-a942c96946d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.3234, -1.9728, -0.2364,  0.1975,  0.4331],\n",
              "         [ 1.7389,  0.9185,  0.0802, -2.0078, -0.3800],\n",
              "         [-0.6194,  0.3353, -1.5344,  2.0479,  0.6247],\n",
              "         [-0.4669,  0.7115,  1.0497,  1.0189, -0.1157]],\n",
              "\n",
              "        [[ 0.5583, -0.1415,  1.6351, -0.1956, -0.8422],\n",
              "         [-0.5781, -0.1813,  0.3092, -1.0998, -0.3213],\n",
              "         [ 1.9954,  1.0051,  0.6116,  0.3715,  0.5064],\n",
              "         [-1.0969, -0.2462, -0.9474,  0.7026, -1.5232]]])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a[:,1:]"
      ],
      "metadata": {
        "id": "ewzICKll1YgJ",
        "outputId": "fe328ca6-6719-456b-d1a0-8637f5c6fd91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 1.7389,  0.9185,  0.0802, -2.0078, -0.3800],\n",
              "         [-0.6194,  0.3353, -1.5344,  2.0479,  0.6247],\n",
              "         [-0.4669,  0.7115,  1.0497,  1.0189, -0.1157]],\n",
              "\n",
              "        [[-0.5781, -0.1813,  0.3092, -1.0998, -0.3213],\n",
              "         [ 1.9954,  1.0051,  0.6116,  0.3715,  0.5064],\n",
              "         [-1.0969, -0.2462, -0.9474,  0.7026, -1.5232]]])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a[:,:-1]"
      ],
      "metadata": {
        "id": "dTcS9p1V1Yix",
        "outputId": "08eceb95-8d33-44b3-cdb2-127b99820e27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.3234, -1.9728, -0.2364,  0.1975,  0.4331],\n",
              "         [ 1.7389,  0.9185,  0.0802, -2.0078, -0.3800],\n",
              "         [-0.6194,  0.3353, -1.5344,  2.0479,  0.6247]],\n",
              "\n",
              "        [[ 0.5583, -0.1415,  1.6351, -0.1956, -0.8422],\n",
              "         [-0.5781, -0.1813,  0.3092, -1.0998, -0.3213],\n",
              "         [ 1.9954,  1.0051,  0.6116,  0.3715,  0.5064]]])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(a[:,1:] - a[:,:-1]).pow(2).flatten().mean()"
      ],
      "metadata": {
        "id": "0Hr6qgLH27Gq",
        "outputId": "8e9c5379-48db-4551-832b-ac04c76c2cef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.7768)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(a[:,1:] - a[:,:-1]).pow(2).mean() # by not selecting an axis, it returns the mean over the flatten tensor"
      ],
      "metadata": {
        "id": "H6feWQYw1l_6",
        "outputId": "729ff72c-2448-49a6-e903-3994903129c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.7768)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vblS5g8exSWi"
      },
      "source": [
        "### Training a Weight-Tied Regularized LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "p9_yS2zaxSWj"
      },
      "outputs": [],
      "source": [
        "class LMModel7(Module):\n",
        "    def __init__(self, vocab_sz, n_hidden, n_layers, p):\n",
        "        self.i_h = nn.Embedding(vocab_sz, n_hidden)\n",
        "        self.rnn = nn.LSTM(n_hidden, n_hidden, n_layers, batch_first=True)\n",
        "        self.drop = nn.Dropout(p)\n",
        "        self.h_o = nn.Linear(n_hidden, vocab_sz)\n",
        "        self.h_o.weight = self.i_h.weight\n",
        "        self.h = [torch.zeros(n_layers, bs, n_hidden) for _ in range(2)]\n",
        "        \n",
        "    def forward(self, x):\n",
        "        raw,h = self.rnn(self.i_h(x), self.h)\n",
        "        out = self.drop(raw)\n",
        "        self.h = [h_.detach() for h_ in h]\n",
        "        return self.h_o(out),raw,out\n",
        "    \n",
        "    def reset(self): \n",
        "        for h in self.h: h.zero_()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "D4AvCCD0xSWj"
      },
      "outputs": [],
      "source": [
        "learn = Learner(dls, LMModel7(len(vocab), 64, 2, 0.5),\n",
        "                loss_func=CrossEntropyLossFlat(), metrics=accuracy,\n",
        "                cbs=[ModelResetter, RNNRegularizer(alpha=2, beta=1)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "HKTNWg_gxSWj"
      },
      "outputs": [],
      "source": [
        "learn = TextLearner(dls, LMModel7(len(vocab), 64, 2, 0.4),\n",
        "                    loss_func=CrossEntropyLossFlat(), metrics=accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "A6S0ts2txSWj",
        "outputId": "0b441c46-ba59-4395-8e8b-7543797e64e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.461772</td>\n",
              "      <td>1.946499</td>\n",
              "      <td>0.509277</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.516597</td>\n",
              "      <td>1.259043</td>\n",
              "      <td>0.637370</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.801910</td>\n",
              "      <td>0.857449</td>\n",
              "      <td>0.779460</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.403068</td>\n",
              "      <td>0.794006</td>\n",
              "      <td>0.790771</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.210353</td>\n",
              "      <td>0.758438</td>\n",
              "      <td>0.823242</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.115219</td>\n",
              "      <td>0.805166</td>\n",
              "      <td>0.826904</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.072490</td>\n",
              "      <td>0.744068</td>\n",
              "      <td>0.830485</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.049464</td>\n",
              "      <td>0.756448</td>\n",
              "      <td>0.844808</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.034863</td>\n",
              "      <td>0.676260</td>\n",
              "      <td>0.847575</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.027905</td>\n",
              "      <td>0.621526</td>\n",
              "      <td>0.868490</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.023950</td>\n",
              "      <td>0.809542</td>\n",
              "      <td>0.830241</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.020251</td>\n",
              "      <td>0.758965</td>\n",
              "      <td>0.839274</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.016902</td>\n",
              "      <td>0.808062</td>\n",
              "      <td>0.831868</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.014254</td>\n",
              "      <td>0.786015</td>\n",
              "      <td>0.836263</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.012717</td>\n",
              "      <td>0.809981</td>\n",
              "      <td>0.834473</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "learn.fit_one_cycle(15, 1e-2, wd=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWIeemZhxSWk"
      },
      "source": [
        "## Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnKNMh9IxSWk"
      },
      "source": [
        "## Questionnaire"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xII0H8OdxSWk"
      },
      "source": [
        "1. If the dataset for your project is so big and complicated that working with it takes a significant amount of time, what should you do?\n",
        "1. Why do we concatenate the documents in our dataset before creating a language model?\n",
        "1. To use a standard fully connected network to predict the fourth word given the previous three words, what two tweaks do we need to make to ou model?\n",
        "1. How can we share a weight matrix across multiple layers in PyTorch?\n",
        "1. Write a module that predicts the third word given the previous two words of a sentence, without peeking.\n",
        "1. What is a recurrent neural network?\n",
        "1. What is \"hidden state\"?\n",
        "1. What is the equivalent of hidden state in ` LMModel1`?\n",
        "1. To maintain the state in an RNN, why is it important to pass the text to the model in order?\n",
        "1. What is an \"unrolled\" representation of an RNN?\n",
        "1. Why can maintaining the hidden state in an RNN lead to memory and performance problems? How do we fix this problem?\n",
        "1. What is \"BPTT\"?\n",
        "1. Write code to print out the first few batches of the validation set, including converting the token IDs back into English strings, as we showed for batches of IMDb data in <<chapter_nlp>>.\n",
        "1. What does the `ModelResetter` callback do? Why do we need it?\n",
        "1. What are the downsides of predicting just one output word for each three input words?\n",
        "1. Why do we need a custom loss function for `LMModel4`?\n",
        "1. Why is the training of `LMModel4` unstable?\n",
        "1. In the unrolled representation, we can see that a recurrent neural network actually has many layers. So why do we need to stack RNNs to get better results?\n",
        "1. Draw a representation of a stacked (multilayer) RNN.\n",
        "1. Why should we get better results in an RNN if we call `detach` less often? Why might this not happen in practice with a simple RNN?\n",
        "1. Why can a deep network result in very large or very small activations? Why does this matter?\n",
        "1. In a computer's floating-point representation of numbers, which numbers are the most precise?\n",
        "1. Why do vanishing gradients prevent training?\n",
        "1. Why does it help to have two hidden states in the LSTM architecture? What is the purpose of each one?\n",
        "1. What are these two states called in an LSTM?\n",
        "1. What is tanh, and how is it related to sigmoid?\n",
        "1. What is the purpose of this code in `LSTMCell`: `h = torch.stack([h, input], dim=1)`\n",
        "1. What does `chunk` do in PyTorch?\n",
        "1. Study the refactored version of `LSTMCell` carefully to ensure you understand how and why it does the same thing as the non-refactored version.\n",
        "1. Why can we use a higher learning rate for `LMModel6`?\n",
        "1. What are the three regularization techniques used in an AWD-LSTM model?\n",
        "1. What is \"dropout\"?\n",
        "1. Why do we scale the weights with dropout? Is this applied during training, inference, or both?\n",
        "1. What is the purpose of this line from `Dropout`: `if not self.training: return x`\n",
        "1. Experiment with `bernoulli_` to understand how it works.\n",
        "1. How do you set your model in training mode in PyTorch? In evaluation mode?\n",
        "1. Write the equation for activation regularization (in math or code, as you prefer). How is it different from weight decay?\n",
        "1. Write the equation for temporal activation regularization (in math or code, as you prefer). Why wouldn't we use this for computer vision problems?\n",
        "1. What is \"weight tying\" in a language model?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5JDWL7GxSWl"
      },
      "source": [
        "### Further Research"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXaU_wUQxSWl"
      },
      "source": [
        "1. In ` LMModel2`, why can `forward` start with `h=0`? Why don't we need to say `h=torch.zeros(...)`?\n",
        "1. Write the code for an LSTM from scratch (you may refer to <<lstm>>).\n",
        "1. Search the internet for the GRU architecture and implement it from scratch, and try training a model. See if you can get results similar to those we saw in this chapter. Compare you results to the results of PyTorch's built in `GRU` module.\n",
        "1. Take a look at the source code for AWD-LSTM in fastai, and try to map each of the lines of code to the concepts shown in this chapter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "Jp_TRYi_xSWl"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "split_at_heading": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "name": "12_chapter_notebook.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}