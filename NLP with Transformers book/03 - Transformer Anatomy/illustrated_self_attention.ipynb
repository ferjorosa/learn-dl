{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d744f54-9f14-4388-a092-675d5f4c2725",
   "metadata": {},
   "source": [
    "# The illustrated self-attention\n",
    "\n",
    "[**Original article**](https://towardsdatascience.com/illustrated-self-attention-2d627e33b20a)\n",
    "\n",
    "Transformer-based architectures, which are primarily used in modelling language understanding tasks, eschew the use of recurrence in neural network (RNNs) and instead trust entirely on self-attention mechanisms to draw global dependencies between inputs and outputs. \n",
    "\n",
    "Attention is a mechanism that allows neural networks to assign a different amount of weight or \"attention\" to each element in a sequence. The \"self\" part in \"self-attention\", refers to the fact that these weights are computed for all hidden states in the same set; for example, all the hidden states of the encoder. By contrast, the attention mechanism associated with recurrent models involves computing the relevance of each encoder hidden state to the decoder hidden state at a given decoding timestep.\n",
    "\n",
    "The main steps for the computation of self-attention are the following:\n",
    "\n",
    "1. Prepare inputs\n",
    "2. Initialise weights\n",
    "3. Derive key, query and value\n",
    "4. Calculate attention scores for Input 1\n",
    "5. Calculate softmax\n",
    "6. Multiply scores with values\n",
    "7. Sum weighted values to get Output 1\n",
    "8. Repeat steps 4–7 for Input 2 & Input 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7f9bee-4dd7-4dad-add1-d74435cbeae5",
   "metadata": {},
   "source": [
    "## Step 1: Prepare inputs\n",
    "\n",
    "For the sake of simplicity, we are going to consider 3 inputs, each with dimension 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e88a618b-66a2-4a68-8b35-2349bead0fd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 0.],\n",
       "        [0., 2., 0., 2.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = [\n",
    "  [1, 0, 1, 0], # Input 1\n",
    "  [0, 2, 0, 2], # Input 2\n",
    "  [1, 1, 1, 1]  # Input 3\n",
    " ]\n",
    "x = torch.tensor(x, dtype=torch.float32)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b5e386-64f4-45b5-9781-a5e4b3c7a831",
   "metadata": {},
   "source": [
    "## Step 2: Initialize weights\n",
    "\n",
    "Every input must have three representations (see diagram below). These representations are called <span style=\"color:orange\"><b>Key</b></span> (<span style=\"color:orange\"><b>K</b></span>), <span style=\"color:red\"><b>Query</b></span> (<span style=\"color:red\"><b>Q</b></span>), and <span style=\"color:purple\"><b>Value</b></span> (<span style=\"color:purple\"><b>V</b></span>). For this example, let’s take that we want these representations to have a dimension of 3. Because every input has a dimension of 4, this means each set of the weights must have a shape of 4×3.\n",
    "\n",
    "<img title=\"\" src=\"images_isa/step_2.gif\" alt=\"\" width=\"800\" data-align=\"center\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c5db78d-618d-4856-901c-8b09f4d40845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights for key: \n",
      " tensor([[0., 0., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 1., 0.]])\n",
      "Weights for query: \n",
      " tensor([[1., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 1.]])\n",
      "Weights for value: \n",
      " tensor([[0., 2., 0.],\n",
      "        [0., 3., 0.],\n",
      "        [1., 0., 3.],\n",
      "        [1., 1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "w_key = [\n",
    "  [0, 0, 1],\n",
    "  [1, 1, 0],\n",
    "  [0, 1, 0],\n",
    "  [1, 1, 0]\n",
    "]\n",
    "w_query = [\n",
    "  [1, 0, 1],\n",
    "  [1, 0, 0],\n",
    "  [0, 0, 1],\n",
    "  [0, 1, 1]\n",
    "]\n",
    "w_value = [\n",
    "  [0, 2, 0],\n",
    "  [0, 3, 0],\n",
    "  [1, 0, 3],\n",
    "  [1, 1, 0]\n",
    "]\n",
    "w_key = torch.tensor(w_key, dtype=torch.float32)\n",
    "w_query = torch.tensor(w_query, dtype=torch.float32)\n",
    "w_value = torch.tensor(w_value, dtype=torch.float32)\n",
    "\n",
    "print(\"Weights for key: \\n\", w_key)\n",
    "print(\"Weights for query: \\n\", w_query)\n",
    "print(\"Weights for value: \\n\", w_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb48890-cbc8-4551-8852-9a8d380a3af7",
   "metadata": {},
   "source": [
    "## Step 3: Derive key, query, and value\n",
    "\n",
    "Obtaining the <span style=\"color:red\"><b>keys</b></span>:\n",
    "\n",
    "```\n",
    "               [0, 0, 1]\n",
    "[1, 0, 1, 0]   [1, 1, 0]   [0, 1, 1]\n",
    "[0, 2, 0, 2] x [0, 1, 0] = [4, 4, 0]\n",
    "[1, 1, 1, 1]   [1, 1, 0]   [2, 3, 1]\n",
    "```\n",
    "\n",
    "Obtaining the <span style=\"color:orange\"><b>queries</b></span>:\n",
    "\n",
    "```\n",
    "               [1, 0, 1]\n",
    "[1, 0, 1, 0]   [1, 0, 0]   [1, 0, 2]\n",
    "[0, 2, 0, 2] x [0, 0, 1] = [2, 2, 2]\n",
    "[1, 1, 1, 1]   [0, 1, 1]   [2, 1, 3]\n",
    "```\n",
    "\n",
    "Obtaining the <span style=\"color:purple\"><b>values</b></span>:\n",
    "\n",
    "```\n",
    "               [0, 2, 0]\n",
    "[1, 0, 1, 0]   [0, 3, 0]   [1, 2, 3] \n",
    "[0, 2, 0, 2] x [1, 0, 3] = [2, 8, 0]\n",
    "[1, 1, 1, 1]   [1, 1, 0]   [2, 6, 3]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "709910b2-5562-4b05-8054-3f39813f2304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: \n",
      " tensor([[0., 1., 1.],\n",
      "        [4., 4., 0.],\n",
      "        [2., 3., 1.]])\n",
      "Querys: \n",
      " tensor([[1., 0., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 1., 3.]])\n",
      "Values: \n",
      " tensor([[1., 2., 3.],\n",
      "        [2., 8., 0.],\n",
      "        [2., 6., 3.]])\n"
     ]
    }
   ],
   "source": [
    "keys = x @ w_key\n",
    "querys = x @ w_query\n",
    "values = x @ w_value\n",
    "\n",
    "print(\"Keys: \\n\", keys)\n",
    "# tensor([[0., 1., 1.],\n",
    "#         [4., 4., 0.],\n",
    "#         [2., 3., 1.]])\n",
    "\n",
    "print(\"Querys: \\n\", querys)\n",
    "# tensor([[1., 0., 2.],\n",
    "#         [2., 2., 2.],\n",
    "#         [2., 1., 3.]])\n",
    "print(\"Values: \\n\", values)\n",
    "# tensor([[1., 2., 3.],\n",
    "#         [2., 8., 0.],\n",
    "#         [2., 6., 3.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bfd9c0-d94f-4245-8299-9db317a99455",
   "metadata": {},
   "source": [
    "## Step 4: Calculate attention scores\n",
    "\n",
    "To obtain **attention scores**, we start off with taking a dot product between Input 1’s <span style=\"color:red\"><b>query</b></span> with <span style=\"color:orange\"><b>all keys</b></span>, including itself. Since there are 3 key representations (because we have 3 inputs), we obtain 3 <span style=\"color:blue\"><b>attention scores</b></span>.\n",
    "\n",
    "```\n",
    "            [0, 4, 2]\n",
    "[1, 0, 2] x [1, 4, 3] = [2, 4, 4]\n",
    "            [1, 0, 1]\n",
    "```\n",
    "Notice that we only use the query from Input 1. Later we’ll work on repeating this same step for the other querys.\n",
    "\n",
    "<img title=\"\" src=\"images_isa/step_4.gif\" alt=\"\" width=\"800\" data-align=\"center\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31ab3a76-ae80-4705-a48b-7484c0fdaccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.,  4.,  4.],\n",
      "        [ 4., 16., 12.],\n",
      "        [ 4., 12., 10.]])\n"
     ]
    }
   ],
   "source": [
    "attn_scores = querys @ keys.T\n",
    "print(attn_scores)\n",
    "\n",
    "# tensor([[ 2.,  4.,  4.],  # attention scores from Query 1\n",
    "#         [ 4., 16., 12.],  # attention scores from Query 2\n",
    "#         [ 4., 12., 10.]]) # attention scores from Query 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096c44f6-5064-4a1d-a893-2592373d4e53",
   "metadata": {},
   "source": [
    "## Step 5: Calculate softmax\n",
    "\n",
    "Take the **softmax** across these **attention scores** (blue).\n",
    "```\n",
    "softmax([2, 4, 4]) = [0.0, 0.5, 0.5]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecc38366-cd07-4eba-9a25-a5001145b2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6.3379e-02, 4.6831e-01, 4.6831e-01],\n",
      "        [6.0337e-06, 9.8201e-01, 1.7986e-02],\n",
      "        [2.9539e-04, 8.8054e-01, 1.1917e-01]])\n",
      "tensor([[0.0000, 0.5000, 0.5000],\n",
      "        [0.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.9000, 0.1000]])\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.functional import softmax\n",
    "\n",
    "attn_scores_softmax = softmax(attn_scores, dim=-1)\n",
    "print(attn_scores_softmax)\n",
    "# tensor([[6.3379e-02, 4.6831e-01, 4.6831e-01],\n",
    "#         [6.0337e-06, 9.8201e-01, 1.7986e-02],\n",
    "#         [2.9539e-04, 8.8054e-01, 1.1917e-01]])\n",
    "\n",
    "# For readability, approximate the above as follows\n",
    "attn_scores_softmax = [\n",
    "  [0.0, 0.5, 0.5],\n",
    "  [0.0, 1.0, 0.0],\n",
    "  [0.0, 0.9, 0.1]\n",
    "]\n",
    "attn_scores_softmax = torch.tensor(attn_scores_softmax)\n",
    "print(attn_scores_softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96ffdbb-b289-4979-8553-7c91269f36f3",
   "metadata": {},
   "source": [
    "## Step 6: Multiply softmaxed scores with values\n",
    "\n",
    "The softmaxed attention scores for each input (blue) is multiplied with its corresponding **value** (purple). This results in 3 alignment vectors (yellow). In this tutorial, we’ll refer to them as **weighted values**.\n",
    "```\n",
    "1: 0.0 * [1, 2, 3] = [0.0, 0.0, 0.0]\n",
    "2: 0.5 * [2, 8, 0] = [1.0, 4.0, 0.0]\n",
    "3: 0.5 * [2, 6, 3] = [1.0, 3.0, 1.5]\n",
    "``` \n",
    "\n",
    "<img title=\"\" src=\"images_isa/step_6.gif\" alt=\"\" width=\"800\" data-align=\"center\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "054db4bb-89bd-4e71-a8bd-87d4533a5808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[1.0000, 4.0000, 0.0000],\n",
      "         [2.0000, 8.0000, 0.0000],\n",
      "         [1.8000, 7.2000, 0.0000]],\n",
      "\n",
      "        [[1.0000, 3.0000, 1.5000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.2000, 0.6000, 0.3000]]])\n"
     ]
    }
   ],
   "source": [
    "weighted_values = values[:,None] * attn_scores_softmax.T[:,:,None]\n",
    "print(weighted_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed85efb-d641-4510-a749-bb7335b048f6",
   "metadata": {},
   "source": [
    "## Step 7: Sum weighted values\n",
    "\n",
    "Take all the **weighted values** (yellow) and sum them element-wise:\n",
    "\n",
    "```\n",
    "  [0.0, 0.0, 0.0]\n",
    "+ [1.0, 4.0, 0.0]\n",
    "+ [1.0, 3.0, 1.5]\n",
    "-----------------\n",
    "= [2.0, 7.0, 1.5]\n",
    "```\n",
    "\n",
    "The resulting vector ```[2.0, 7.0, 1.5]``` (dark green) **is Output 1**, which is based on the **query representation from Input 1** interacting with all other keys, including itself.\n",
    "\n",
    "<img title=\"\" src=\"images_isa/step_7.gif\" alt=\"\" width=\"800\" data-align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39cdeb2-811a-4ca4-a3e2-c80e32a821b8",
   "metadata": {},
   "source": [
    "### Step 8: Repeat for Input 2 & Input 3\n",
    "\n",
    "<img title=\"\" src=\"images_isa/step_8.gif\" alt=\"\" width=\"800\" data-align=\"center\">\n",
    "\n",
    "Note: *The dimension of **query** and **key** must always be the same because of the dot product score function. However, the dimension of **value** may be different from **query** and **key**. The resulting output will consequently follow the dimension of **value**.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2418bb0-f67d-423f-ac26-06f20e533fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.0000, 7.0000, 1.5000],\n",
      "        [2.0000, 8.0000, 0.0000],\n",
      "        [2.0000, 7.8000, 0.3000]])\n"
     ]
    }
   ],
   "source": [
    "outputs = weighted_values.sum(dim=0)\n",
    "print(outputs)\n",
    "\n",
    "# tensor([[2.0000, 7.0000, 1.5000],  # Output 1\n",
    "#         [2.0000, 8.0000, 0.0000],  # Output 2\n",
    "#         [2.0000, 7.8000, 0.3000]]) # Output 3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
